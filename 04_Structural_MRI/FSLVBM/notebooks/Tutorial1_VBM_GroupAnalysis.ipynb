{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voxel Based Morphometry (VBM) analysis with FSL\n",
    "\n",
    "\n",
    "This notebook is an edited version of the FSL-VBM tutorial to match what we will cover during GOGNESTIC. The full official FSL course tutorials, as well as the FSL-VBM userâ€™s guide, are available here:\n",
    "\n",
    "https://fsl.fmrib.ox.ac.uk/fslcourse/2019_Beijing/lectures/Structural/seg_struct.html\n",
    "\n",
    "https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/FSLVBM/UserGuide\n",
    "\n",
    "\n",
    "## FSL-VBM for group comparison\n",
    "\n",
    "In this session we look at a small ageing study comparing two groups (data_2groups, young and older healthy controls) for local differences in grey matter volume, using FSL-VBM. We will also look at another ageing dataset (data_Age) to see how we can use FSL-VBM to look for correlations between grey matter volume and a continuous measure (age, cognitive test score, etc). Most of the steps have already been carried out, as there isn't enough time in this session to run all of the registrations required to carry out a full analysis from scratch, but you can re-run these later in your own time. \n",
    "\n",
    "## FSL-VBM Pipeline - Overview\n",
    "\n",
    "Running FSL-VBM involves a few simple steps: \n",
    "\n",
    "*\tprepare your T1-weighted images in the right format \n",
    "*\tfslvbm_1_bet - carry out brain extraction on all T1 images \n",
    "*\tfslvbm_2_template - create the study-specific symmetric grey matter template \n",
    "*\tfslvbm_3_proc - register all the grey matter images to the template, modulate and smooth them with different kernel sizes and finally runs an initial GLM analysis for qualitative evaluation \n",
    "*\trandomise - carry out voxelwise GLM analysis using permutation testing \n",
    "\n",
    "\n",
    "## Step 1 - Prepare your data for the FSL-VBM study\n",
    "\n",
    "#### A. Place all your T1-weighted data in your FSL-VBM directory. \n",
    "\n",
    "Start by creating a new directory, and then copy into your FSL-VBM directory all of your subjects' T1 images, giving each subject's T1 image a different name, preferably with a prefix corresponding to each group. **This step has already been carried out for this tutorial.**  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import general modules\n",
    "import os\n",
    "import glob\n",
    "import subprocess\n",
    "\n",
    "#set up paths\n",
    "notebook_dir = \"/home/cognestic/COGNESTIC/04_Structural_MRI/FSLVBM/notebooks\"\n",
    "data_dir = \"/home/cognestic/COGNESTIC/04_Structural_MRI/FSLVBM/data\"\n",
    "vbm_dir = f\"{data_dir}/data_2groups/FSLVBM\"\n",
    "\n",
    "#list the T1 files in FSLVBM directory\n",
    "T1_files = glob.glob(f\"{vbm_dir}/*_T1.nii.gz\")\n",
    "\n",
    "for item in T1_files:\n",
    "    print(item[-23:])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B. Select subjects to create a study-specific template. \n",
    "\n",
    "If you have more than one group and the number of subjects in each is not the same, choose (at random) among the biggest group(s) the images that you will use to create the study-specific template, with the same number as of the smallest group (in order to create an unbiased template - see below for further explanation). Once you've chosen which T1 images to keep to build the template, put all the selected names of exams in a file called template_list in your FSL-VBM directory.\n",
    "\n",
    "All your different populations included in this study MUST be represented in the template construction. \n",
    "\n",
    "If you are using all datasets, simply run the following: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = f\"{vbm_dir}/template_list\"\n",
    "\n",
    "with open(output_file, \"w\") as file:\n",
    "    for item in T1_files:\n",
    "        file.write(f\"{item[-23:]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C. Check your data\n",
    "\n",
    "At this point you should have a quick look at all your data to check that all subjects' structural images are what you expected. The slicesdir command takes the list of images and creates a simple web-page containing snapshots for each of the images. Once it has finished running it tells you the name of the web page to open in your web browser, to view the snapshots. Have a careful look. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change to vbm directory\n",
    "os.chdir(vbm_dir)\n",
    "\n",
    "#check if a slicesdir folder exists within the fslvbm directory, which would suggest that the slicesdir command has been run\n",
    "slicesdir_path = f\"{vbm_dir}/slicesdir\"\n",
    "\n",
    "#if slicesdir has not been run, run it to inspect the FA data\n",
    "if not os.path.exists(slicesdir_path):\n",
    "\n",
    "    #run slicesdir to inspect the T1 data\n",
    "\n",
    "    #set up the command\n",
    "    command = \"slicesdir *.nii.gz\"\n",
    "\n",
    "    # Execute the command\n",
    "    try:\n",
    "        result = subprocess.run(command, shell=True, check=True, text=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "        html_file = [f for f in os.listdir(f\"{vbm_dir}/slicesdir\") if f.endswith('.html')]\n",
    "        print(f\"slicesdir completed successfully. To visualise the output, open the following link in your browser: file:///{vbm_dir}/slicesdir/{html_file[0]}\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        print(\"Output:\\n\", e.stdout)\n",
    "        print(\"Errors:\\n\", e.stderr)\n",
    "\n",
    "else:\n",
    "    html_file = [f for f in os.listdir(f\"{vbm_dir}/slicesdir\") if f.endswith('.html')]\n",
    "    print(f\"slicesdir folder has already been created. To visualise the output, open the following link in your browser: file:///{vbm_dir}/slicesdir/{html_file[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### D. Create your design matrix and contrast files\n",
    "\n",
    "It is a good idea to consider your cross-subject statistical model before you run the FSL-VBM analysis. So you should at this point create your design.mat and design.con in your FSL-VBM directory; see some FSL GLM examples here https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/GLM. For simple experimental design with just two groups you can also use the script design_ttest2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creat the design matrix and contrast files for comparing two groups of 10 pariticpants each \n",
    "command = \"design_ttest2 design 10 10\"\n",
    "\n",
    "# Execute the command\n",
    "try:\n",
    "    result = subprocess.run(command, shell=True, check=True, text=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "    print('design_ttest2 completed successfully.')\n",
    "except subprocess.CalledProcessError as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "    print(\"Output:\\n\", e.stdout)\n",
    "    print(\"Errors:\\n\", e.stderr)\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WARNING!!! The order of the rows in your design.mat model MUST match the order of your images in the FSL-VBM directory (alphabetical order). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 - Extracting brain information: fslvbm_1_bet\n",
    "\n",
    "The first FSL-VBM script moves all your input images into a new struc subdirectory (and adding \"_struc\" to the end of each filename). It then runs brain extraction on the images. You can either use the -b option to get default BET behaviour, or use the -N option if your images include a lot of neck (which most of the time confounds the BET preprocessing). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change to vbm directory\n",
    "os.chdir(vbm_dir)\n",
    "\n",
    "#check if a struct folder exists within the fslvbm directory, which would suggest that the fslvbm_1_bet command has been run\n",
    "struc_path = f\"{vbm_dir}/struc\"\n",
    "\n",
    "#if fslvbm_1_bet has not been run, run it now \n",
    "if not os.path.exists(struc_path):\n",
    "\n",
    "    #run fslvbm_1_bet\n",
    "\n",
    "    #set up the command\n",
    "    command = \"fslvbm_1_bet -N\"\n",
    "\n",
    "    # Execute the command\n",
    "    try:\n",
    "        result = subprocess.run(command, shell=True, check=True, text=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "        print('fslvbm_1_bet completed successfully.')\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        print(\"Output:\\n\", e.stdout)\n",
    "        print(\"Errors:\\n\", e.stderr)\n",
    "\n",
    "#Inspect the data using the slicesdir output after fslvbm_1_bet\n",
    "\n",
    "html_file = [f for f in os.listdir(f\"{vbm_dir}/struc/slicesdir\") if f.endswith('.html')]\n",
    "print(f\"To visualise the output after fslvbm_1_bet, open the following link in your browser: file:///{vbm_dir}/struc/slicesdir/{html_file[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LOOK AT YOUR DATA\n",
    "\n",
    "At the end of this step, it is once again worth CHECKING the brain images (*_brain.*) in your struc directory by loading the new slicesdir output into a web browser. Brain extraction is the step which is the most likely to need tweaking in the FSL-VBM protocol. It might not be too much of an issue if you get \"more\" than the grey matter (eyes, dura etc.) though this will need careful checking before running your statistics. If you do not get good results with either option (i.e., if some images are missing some grey matter), you can try adding other bet options after the -b or -N option. \n",
    "\n",
    "If you later want to add more subjects to your analysis then just put the new subjects' images inside the top level directory (e.g. FSLVBM) and re-run fslvbm_1_bet. Don't forget to update template_list if necessary. \n",
    "\n",
    "\n",
    "\n",
    "## Step 3 - Creating the template: fslvbm_2_template\n",
    "\n",
    "The second step of the FSL-VBM protocol creates the study-specific grey matter (GM) template. \n",
    "\n",
    "First, all brain-extracted images are segmented into GM, WM and CSF. Then, GM images selected in the template_list file (*_struc_GM) are affine-registered to the GM ICBM-152 template, concatenated and averaged. This averaged image is then flipped along the x-axis and the two mirror images then re-averaged to obtain a first-pass, study-specific \"affine\" GM template (\"template_GM_init\"). Second, the template_list GM images are re-registered to this \"affine\" GM template using non-linear registration, concatenated into a 4D image called \"template_4D_GM\", averaged, flipped along the x-axis. Both mirror images are then averaged to create the final symmetric, study-specific \"non-linear\" GM template at 2x2x2mm<sup>3</sup> resolution in standard space.\n",
    "\n",
    "If you have different populations, they should all be represented in your template. You should use the same number of subjects from each in the construction of the study-specific template. This is to avoid any bias during the registration step that would have consisted in favouring one of the groups. For example, if you have only controls in your template, or more controls than patients, it is likely that the non-linear registration would be more accurate for your control subjects than for your patients. Then you cannot distinguish, in your results showing differences in the GM volume distribution between the two groups, what is actually disease-related from what is registration-related! \n",
    "\n",
    "For this step, you have two options: either you want to create a template based on an affine registration (-a option) of GM images to the GM ICBM-152 template, or on a non-linear registration (-n option). The non-linear (-n) option is usually recommended. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change to vbm directory\n",
    "os.chdir(vbm_dir)\n",
    "\n",
    "#check if the file template_GM.nii.gz exists within the fslvbm/struc directory, which would suggest that the fslvbm_2_template command has been run\n",
    "template_path = f\"{vbm_dir}/struc/template_GM.nii.gz\"\n",
    "\n",
    "#if tbss_2_template has not been run, run it now\n",
    "if not os.path.exists(template_path):\n",
    "\n",
    "    #run fslvbm_2_template\n",
    "\n",
    "    #set up the command\n",
    "    command = f\"fslvbm_2_template -n\"\n",
    "\n",
    "    # Execute the command\n",
    "    try:\n",
    "        result = subprocess.run(command, shell=True, check=True, text=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "        print('fslvbm_2_template completed successfully.')\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        print(\"Output:\\n\", e.stdout)\n",
    "        print(\"Errors:\\n\", e.stderr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once this is completed, we can check the template_GM.nii.gz image in the struc folder: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import image\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage import rotate\n",
    "\n",
    "#load the GM template\n",
    "GM_template = image.load_img(f\"{vbm_dir}/struc/template_GM.nii.gz\")\n",
    "GM_template_data = GM_template.get_fdata()\n",
    "\n",
    "#set up the subplots\n",
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(10, 10), subplot_kw={'xticks': [], 'yticks': []})\n",
    "\n",
    "axes[0].imshow(rotate(GM_template_data[:,:,46], -90), cmap='gray', origin='lower')\n",
    "axes[0].set_title(\"GM template, axial view\")\n",
    "\n",
    "axes[1].imshow(rotate(GM_template_data[:,54,:], -90), cmap='gray', origin='lower')\n",
    "axes[1].set_title(\"GM template, coronal view\")\n",
    "\n",
    "axes[2].imshow(rotate(GM_template_data[46,:,:], -90), cmap='gray', origin='lower')\n",
    "axes[2].set_title(\"GM template, sagittal view\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 - Processing the native GM images: fslvbm_3_proc\n",
    "\n",
    "The final script will non-linearly register all your GM images to the study-specific template and concatenate them into a 4D image (\"GM_merg\") in the stats directory in your working FSL-VBM directory. \n",
    "\n",
    "The FSL-VBM protocol also introduces a compensation (or \"modulation\") for the contraction/enlargement due to the non-linear component of the transformation: each voxel of each registered grey matter image is multiplied by the Jacobian of the warp field (see Good et al., 2001). All the modulated registered GM images are concatenated into a 4D image in the stats directory (\"GM_mod_merg\") and then smoothed (\"GM_mod_merg_s3\" for instance) by a range of Gaussian kernels; sigma = 2, 3, 4mm, i.e., approximately from FWHM = 2x2.3 = 4.6mm to FWHM = 9mm.\n",
    "\n",
    "Finally, this last step gets everything ready for you to run permutation-based non-parametric inference using the design.mat and design.con which you supplied, a mask of the GM (\"GM_mask\") and the 4D multi-subject concatenated processed data (e.g. \"GM_mod_merg_s3\"). The script runs randomise with inference (generation of p-value maps) turned off, so that it very quickly creates just the raw tstat maps. These tstats maps should help you decide which smoothing is the most relevant to feed into a full run of randomise, and which threshold to use for the cluster-based thresholding (option -c in the randomise command); however, in general we would recommend using the TFCE option (-T) instead of the cluster-based thresholding. \n",
    "\n",
    "WARNING!!! By default fslvbm_3_proc concatenates the images in alphabetical order (following the names that they started with); make sure this matches the subject ordering assumed in your design.mat model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change to vbm directory\n",
    "os.chdir(vbm_dir)\n",
    "\n",
    "#check if the directory stats exists within the fslvbm directory, which would suggest that the fslvbm_3_proc command has been run\n",
    "stats_path = f\"{vbm_dir}/stats\"\n",
    "\n",
    "#if tbss_3_proc has not been run, run it now\n",
    "if not os.path.exists(stats_path):\n",
    "\n",
    "    #run fslvbm_3_proc\n",
    "\n",
    "    #set up the command\n",
    "    command = \"fslvbm_3_proc\"\n",
    "\n",
    "    # Execute the command\n",
    "    try:\n",
    "        result = subprocess.run(command, shell=True, check=True, text=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "        print('fslvbm_3_proc completed successfully.')\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        print(\"Output:\\n\", e.stdout)\n",
    "        print(\"Errors:\\n\", e.stderr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5 - Obtaining and displaying your FSL-VBM results\n",
    "\n",
    "We strongly recommend using randomise (permutation testing) for inference in VBM-style analysis and not Gaussian random field theory (GRF), as the approximations underlying the latter are not generally appropriate in such analyses. For more detail see the Randomise manual https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/Randomise/UserGuide.\n",
    "\n",
    "### Choosing the level of smoothing\n",
    "\n",
    "Before running randomise for permutation testing, we need to choose the most appropriate smoothing (e.g., sigma=3mm) for the TFCE-based analysis. \n",
    "\n",
    "#### Why smoothing?\n",
    "\n",
    "Smoothing makes it harder to interpret the results because it will average the signal over neighbouring voxelx, leading to a local GM average density. However, there are some statistical benefits:\n",
    "\n",
    "1. Smoothing compensates for some spatial registration error; it helps to accommodate individual differences in brain anatomy that might not be perfectly aligned even after spatial normalization.\n",
    "\n",
    "2. Increased statistical power: smothing supresses noise (as long as the signal of interest is not smoothed out).\n",
    "\n",
    "#### How much smoothing should be applied?\n",
    "\n",
    "1. There is no right answer. \n",
    " \n",
    "2. Check different levels, to see what is consistent and present at all levels of smoothing.\n",
    "\n",
    "3. Decide what is best for your data:\n",
    "    \n",
    "    * For larger areas, the results will be more sensitive with more smoothing applied.\n",
    "\n",
    "    * If smaller biologically plausible areas can be seen on t-maps, then less smoothing would be better.\n",
    "\n",
    "    * The ammount of smoothing changes the relative sensitivity of the methods to different ized regions. \n",
    "\n",
    "4. Always report and justify the level of smoothing used for every publication. \n",
    "\n",
    "To help you decide between smoothing levels, you can loook at the output from fslvbm_3_proc:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#look at the different smoothing levels\n",
    "\n",
    "#import the modules required for visualisation\n",
    "import numpy as np\n",
    "from nilearn import image, plotting\n",
    "\n",
    "#path to FSLDIR\n",
    "fsldir_path = os.environ.get('FSLDIR')\n",
    "\n",
    "#load images\n",
    "background_img = image.load_img(f\"{fsldir_path}/data/standard/MNI152_T1_1mm.nii.gz\")\n",
    "s2_img = image.load_img(f\"{vbm_dir}/stats/GM_mod_merg_s2_tstat2.nii.gz\")\n",
    "s3_img = image.load_img(f\"{vbm_dir}/stats/GM_mod_merg_s3_tstat2.nii.gz\")\n",
    "s4_img = image.load_img(f\"{vbm_dir}/stats/GM_mod_merg_s4_tstat2.nii.gz\")\n",
    "\n",
    "#theshold the t-maps maps to show only values between 3 and 16\n",
    "data_s2 = s2_img.get_fdata()\n",
    "thresholded_data_s2 = np.where((data_s2 >= 2) & (data_s2 <= 16), data_s2, 0)\n",
    "data_s3 = s3_img.get_fdata()\n",
    "thresholded_data_s3 = np.where((data_s3 >= 2) & (data_s3 <= 16), data_s3, 0)\n",
    "data_s4 = s4_img.get_fdata()\n",
    "thresholded_data_s4 = np.where((data_s4 >= 2) & (data_s4 <= 16), data_s4, 0)\n",
    "\n",
    "# Create a new Nilearn image object with the thresholded data\n",
    "thresholded_img_s2 = image.new_img_like(s2_img, thresholded_data_s2)\n",
    "thresholded_img_s3 = image.new_img_like(s3_img, thresholded_data_s3)\n",
    "thresholded_img_s4 = image.new_img_like(s4_img, thresholded_data_s4)\n",
    "\n",
    "# Plotting the background image with the overlays\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(24, 6),\n",
    "                        subplot_kw={'xticks': [], 'yticks': []})\n",
    "\n",
    "display1 = plotting.plot_anat(background_img, display_mode='ortho', axes=axes[0], title='smoothing: sigma = 2mm')\n",
    "display1.add_overlay(thresholded_img_s2, cmap=plt.cm.hot, transparency=0.7)  # Using 'hot' colormap\n",
    "\n",
    "display2 = plotting.plot_anat(background_img, display_mode='ortho', axes=axes[1], title='smoothing: sigma = 3mm')\n",
    "display2.add_overlay(thresholded_img_s3, cmap=plt.cm.hot, transparency=0.7)  # Using 'hot' colormap\n",
    "\n",
    "display3 = plotting.plot_anat(background_img, display_mode='ortho', axes=axes[2], title='smoothing: sigma = 4mm')\n",
    "display3.add_overlay(thresholded_img_s4, cmap=plt.cm.hot, transparency=0.7)  # Using 'hot' colormap\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to apply a different smoothing than already applied, you can do so (e.g., sigma=3.5mm) using fslmaths: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change into the stats directory\n",
    "os.chdir(f\"{vbm_dir}/stats\")\n",
    "\n",
    "#set up the command to apply smoothing with sigma = 3.5mm\n",
    "command = \"fslmaths GM_mod_merg -s 3.5 GM_mod_merg_s3.5\"\n",
    "\n",
    "# Execute the command\n",
    "try:\n",
    "    result = subprocess.run(command, shell=True, check=True, text=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "    print('Smoothing applied successfully.')\n",
    "except subprocess.CalledProcessError as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "    print(\"Output:\\n\", e.stdout)\n",
    "    print(\"Errors:\\n\", e.stderr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running randomise and displaying TFCE-based thresholding results\n",
    "\n",
    "Having chosen the most appropriate smoothing (e.g. sigma = 3mm), run permutation testing with randomise. Typically you would run 5000 permutations, but in the interest of time we will run just 500:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change into the stats directory\n",
    "os.chdir(f\"{vbm_dir}/stats\")\n",
    "\n",
    "#check if the fslvbm_tfce_corrp_tstat1.nii.gz file exists within the fslvbm/stats directory, which would suggest that the randomise step has been run \n",
    "corrp_file_path = f\"{vbm_dir}/stats/fslvbm_tfce_corrp_tstat1.nii.gz\"\n",
    "\n",
    "#if the skeletonised data does not exist, run randomise\n",
    "if not os.path.exists(corrp_file_path):\n",
    "\n",
    "    #set up the command to run randomise with 500 permutations\n",
    "    command = (\n",
    "        f'randomise -i GM_mod_merg_s3 '\n",
    "        f'-o fslvbm '\n",
    "        f'-m GM_mask '\n",
    "        f'-d design.mat '\n",
    "        f'-t design.con '\n",
    "        f'-n 500 '\n",
    "        f'-T ' \n",
    "    )\n",
    "\n",
    "    # Execute the command\n",
    "    try:\n",
    "        result = subprocess.run(command, shell=True, check=True, text=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "        print('randomise completed successfully.')\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        print(\"Output:\\n\", e.stdout)\n",
    "        print(\"Errors:\\n\", e.stderr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contrast 1 gives the GM(old) > GM(young) test. The raw unthresholded tstat image is fslvbm_tstat1 and the corresponding (p-values corrected for multiple comparisons) cluster image is fslvbm_tfce_corrp_tstat1.\n",
    "\n",
    "Thresholding clusters at 0.95 (corresponding to thresholding the p-values at 0.05, because randomise outputs p-values as 1-p for convenience of display - so that higher values are more significant). The following shows the corrected significant values in red-yellow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the images\n",
    "background_img = image.load_img(f\"{fsldir_path}/data/standard/MNI152_T1_1mm.nii.gz\")\n",
    "overlay_img = image.load_img(f\"{vbm_dir}/stats/fslvbm_tfce_corrp_tstat1.nii.gz\")\n",
    "\n",
    "#theshold the significance map to show only values between 0.95 and 1 to keep only significant voxels\n",
    "data = overlay_img.get_fdata()\n",
    "thresholded_data = np.where((data >= 0.95) & (data <= 1), data, 0)\n",
    "\n",
    "# Create a new Nilearn image object with the thresholded data\n",
    "thresholded_img = image.new_img_like(overlay_img, thresholded_data)\n",
    "\n",
    "# Plotting the background image with the overlay\n",
    "display = plotting.plot_anat(background_img, display_mode='ortho')\n",
    "display.add_overlay(thresholded_img, cmap=plt.cm.hot, transparency=0.7)  # Using 'hot' colormap\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do not see any red-yellow in the plot above, which means that there are no significant clusters for contrast 1. This is in line with the expectations from the literature, which suggests GM volume generally decreaeses with age. Contrast 2 gives the GM(old) < GM(young) test, and the figure below shows the corrected significant values in green-blue:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the overlay image\n",
    "overlay_img = image.load_img(f\"{vbm_dir}/stats/fslvbm_tfce_corrp_tstat2.nii.gz\")\n",
    "\n",
    "#theshold the significance map to show only values between 0.95 and 1 to keep only significant voxels\n",
    "data = overlay_img.get_fdata()\n",
    "thresholded_data = np.where((data >= 0.95) & (data <= 1), data, 0)\n",
    "\n",
    "# Create a new Nilearn image object with the thresholded data\n",
    "thresholded_img = image.new_img_like(overlay_img, thresholded_data)\n",
    "\n",
    "# Plotting the background image with the overlay\n",
    "display = plotting.plot_anat(background_img, display_mode='ortho')\n",
    "display.add_overlay(thresholded_img, cmap=plt.cm.winter_r, transparency=0.7)  # Using 'winter' colormap\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This simple group analysis reveals widespread decline of GM density with age, which is in line with previous reports in the Ageing literature.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
