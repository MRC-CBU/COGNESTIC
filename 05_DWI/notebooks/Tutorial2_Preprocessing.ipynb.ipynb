{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing of DWI data\n",
    "\n",
    "\n",
    "Before we can apply any model fitting to our data, we first need to apply a number of pre-processing steps to improve data quality and mitigation of artefacts. First we must load the AP and PA data, using the tools covered in Tutorial 1.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load general modules\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "#load dipy modules\n",
    "import dipy\n",
    "from dipy.io.image import load_nifti, save_nifti\n",
    "from dipy.io.gradients import read_bvals_bvecs\n",
    "\n",
    "\n",
    "#load modules for visualizations\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#define the paths to the data\n",
    "scripts_dir = os.getcwd()\n",
    "bids_dir = \"../data/bids\"\n",
    "out_dir = \"../data/derivatives\"\n",
    "\n",
    "#subject code to be used in this example\n",
    "sub='01'\n",
    "\n",
    "#define path to dwi data\n",
    "dwi_path = f\"{bids_dir}/sub-{sub}/dwi\"\n",
    "\n",
    "#find the relevant files and save file names into specific variables\n",
    "\n",
    "for item in os.listdir(dwi_path):\n",
    "    if item.endswith('AP_dwi.nii'):\n",
    "        dwi_ap_file = item\n",
    "    if item.endswith('AP_dwi.bvec'):\n",
    "        dwi_ap_bvec = item\n",
    "    if item.endswith('AP_dwi.bval'):\n",
    "        dwi_ap_bval = item\n",
    "    if item.endswith('PA_dwi.nii'):\n",
    "        dwi_pa_file = item\n",
    "\n",
    "\n",
    "#load the dwi raw data for phase encoding direction AP\n",
    "dwi_ap_data, dwi_ap_affine = load_nifti(f\"{dwi_path}/{dwi_ap_file}\")\n",
    "\n",
    "#load bvals and bevecs for phase encoding direction AP\n",
    "bvals, bvecs = read_bvals_bvecs(f\"{dwi_path}/{dwi_ap_bval}\", f\"{dwi_path}/{dwi_ap_bvec}\")\n",
    "\n",
    "#load the dwi raw data for phase encoding direction PA\n",
    "dwi_pa_data, dwi_pa_affine = load_nifti(f\"{dwi_path}/{dwi_pa_file}\")\n",
    "\n",
    "#check if a folder already exists for the output data for this subject, create it if not\n",
    "preproc_path = f\"{out_dir}/preprocessing/sub-{sub}\"\n",
    "\n",
    "if not os.path.exists(preproc_path):\n",
    "    os.makedirs(preproc_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Denoising (optional)\n",
    "\n",
    "The first (optional) pre-processing step for diffusion MRI data is denoising. Interpolation or smoothing in other processing steps, such as motion and distortion correction, may alter the noise characteristics and thus violate the assumptions upon which the denoising algorithm is based. Therefore image denoising must be performed as the first step of the image-processing pipeline. Here we will use the Marcenko-Pastur PCA algorithm for denoising. \n",
    "\n",
    "Internally, the mppca algorithm denoises the diffusion-weighted data using a 3D sliding window which is defined by the variable patch_radius. In total, this window should comprise a larger number of voxels than the number of diffusion-weighted volumes. Since our data has a total of 102 volumes, the patch_radius is set to 2 which corresponds to a 5x5x5 sliding window comprising a total of 125 voxels.\n",
    "\n",
    "This can take a long time depending on the size of your dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "# load main pca function using Marcenko-Pastur distribution\n",
    "from dipy.denoise.localpca import mppca\n",
    "\n",
    "#select the middle slice \n",
    "mid_slice = dwi_ap_data.shape[2] // 2\n",
    "\n",
    "#check whether this step has been previously run\n",
    "den_file_path = f\"{out_dir}/preprocessing/sub-{sub}/denoised_ap_mppca.nii.gz\"\n",
    "\n",
    "#if denoising has not been run, run the denoising step\n",
    "if not os.path.exists(den_file_path):\n",
    "\n",
    "    # denoise the dwi data using local MP-PCA\n",
    "    t = time()\n",
    "\n",
    "    #denoise the full dataset - takes 5-6 minutes to run\n",
    "    denoised_ap = mppca(dwi_ap_data, patch_radius=2)\n",
    "\n",
    "    print(\"Time taken for local MP-PCA \", -t + time())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To assess the performance of the denoising algorithm, we can now plot the orginal data, denoised data and the residuals. We always recommend eyeballing the residuals, i.e. original - denoised, as part of the quality control. The lack of anatomy in the residual maps is a marker of accuracy and signal-preservation during denoising. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if the denoising had been run previous, load the denoised data\n",
    "den_file_path = f\"{out_dir}/preprocessing/sub-{sub}/denoised_ap_mppca.nii.gz\"\n",
    "\n",
    "if 'denoised_ap' not in locals():\n",
    "    denoised_ap, _ = load_nifti(den_file_path)\n",
    "\n",
    "#select the middle slice \n",
    "mid_slice_den = denoised_ap.shape[2] // 2\n",
    "\n",
    "#select a volume for the highes b-value, where denoising is most important\n",
    "bval_id = np.where(bvals == max(bvals))[0][0]\n",
    "\n",
    "orig = dwi_ap_data[:, :, mid_slice, bval_id]\n",
    "den = denoised_ap[:, :, mid_slice_den, bval_id]\n",
    "rms_diff = np.sqrt((orig - den) ** 2)\n",
    "\n",
    "fig1, ax = plt.subplots(1, 3, figsize=(16, 6),\n",
    "                        subplot_kw={'xticks': [], 'yticks': []})\n",
    "\n",
    "fig1.subplots_adjust(hspace=0.3, wspace=0.05)\n",
    "\n",
    "ax.flat[0].imshow(orig.T, cmap='gray', interpolation='none',\n",
    "                  origin='lower')\n",
    "ax.flat[0].set_title('Original')\n",
    "ax.flat[1].imshow(den.T, cmap='gray', interpolation='none',\n",
    "                  origin='lower')\n",
    "ax.flat[1].set_title('Denoised Output')\n",
    "ax.flat[2].imshow(rms_diff.T, cmap='gray', interpolation='none',\n",
    "                  origin='lower')\n",
    "ax.flat[2].set_title('Residuals')\n",
    "\n",
    "fig1.savefig(f\"{out_dir}/preprocessing/sub-{sub}/denoised_mppca.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can save the denoised data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check whether the denoised file exists\n",
    "den_file_path = f\"{out_dir}/preprocessing/sub-{sub}/denoised_ap_mppca.nii.gz\"\n",
    "\n",
    "#if the file doesn't exist, save the denoised data\n",
    "if not os.path.exists(den_file_path):\n",
    "    save_nifti(den_file_path, denoised_ap, dwi_ap_affine)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removal of Gibbs artefacts (optional)\n",
    "\n",
    "Gibbs artefacts can be seen as intensity oscillations near the edges of different tissue types. These are a consequence of how we collect and reconstruct MRI data: MRI images are reconstructed from the Fourier coefficients of the k-space data collected during MRI acquisition; in theory, the Frourier series has infinite terms, but in practice we can only have a finite number of coefficients, and it is this series truncation which can lead to artefacts. Gibbs artefacts can affect all MRI modalities, but they can be particularly problematic for diffusion MRI data, as these are usually acquired with a small field of view. \n",
    "\n",
    "Gibbs correction should run on data directly after it has been reconstructed by the scanner, before any interpolation of any kind has taken place. You should not run this command after any form of motion correction for example. However, if you intend on denoising your data, you should do so before Gibbs removal so to not alter the noise structure, which would impact the performance of the denoising algorithm.\n",
    "\n",
    "The algorithm implemented in dipy is based on the sub-voxel Gibbs suppression procedure described by Kellner and colleagues in their 2016 paper (REF). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dipy.denoise.gibbs import gibbs_removal\n",
    "\n",
    "#check whether the Gibbs corrected file exists and if it doesn't, run the Gibbs correction\n",
    "gibbs_file_path = f\"{out_dir}/preprocessing/sub-{sub}/nogibbs_ap_mppca.nii.gz\"\n",
    "\n",
    "if not os.path.exists(gibbs_file_path):\n",
    "\n",
    "    #load the whole brain denoised data from previously saved file\n",
    "    den_file_path = f\"{out_dir}/preprocessing/sub-{sub}/denoised_ap_mppca.nii.gz\"\n",
    "    denoised_ap, den_ap_affine = load_nifti(den_file_path)\n",
    "\n",
    "    #apply the Gibbs removal algorithm to the data   \n",
    "    nogibbs_ap = gibbs_removal(denoised_ap, slice_axis=2, num_processes=-1)\n",
    "\n",
    "    #save the Gibbs corrected data\n",
    "    save_nifti(f\"{out_dir}/preprocessing/sub-{sub}/nogibbs_ap_mppca.nii.gz\", nogibbs_ap, dwi_ap_affine)\n",
    "\n",
    "else:\n",
    "    nogibbs_ap, _ = load_nifti(gibbs_file_path)\n",
    "\n",
    "#visualise the impact of Gibbs correction on the b0 image\n",
    "fig2, ax = plt.subplots(1, 3, figsize=(16, 6),\n",
    "                        subplot_kw={'xticks': [], 'yticks': []})\n",
    "\n",
    "ax.flat[0].imshow(denoised_ap[:, :, mid_slice, 0].T, cmap='gray',  interpolation='none' , origin='lower')\n",
    "ax.flat[0].set_title('Uncorrected b0')\n",
    "ax.flat[1].imshow(nogibbs_ap[:, :, mid_slice, 0].T, cmap='gray', interpolation='none', origin='lower')\n",
    "ax.flat[1].set_title('Corrected b0')\n",
    "ax.flat[2].imshow(nogibbs_ap[:, :, mid_slice, 0].T - denoised_ap[:, :,mid_slice, 0].T, cmap='gray', interpolation='none', origin='lower', vmin=-1000, vmax=1000)\n",
    "ax.flat[2].set_title('Gibbs residuals')\n",
    "\n",
    "plt.show()\n",
    "#fig2.savefig('Gibbs_suppression_b0.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EPI distortion correction\n",
    "\n",
    "In Tutorial 1 we saw that EPI images are affected by distortions which are caused by differences in the magnetic susceptibilities of the areas being imaged. The 'state-of-the-art' method to correct for these distortions is a tool called TOPUP, which is part of the FSL software (https://fsl.fmrib.ox.ac.uk/fsl/fslwiki). We will be calling this tool from our python script using the python subprocess module. Please note that it is a prerequisite that FSL is installed on your system and its binaries are included in your system's path. \n",
    "\n",
    "\n",
    "### TOPUP - Correcting for Susceptibility-induced Distortions \n",
    "\n",
    "FSL topup wiki: https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/topup \n",
    "\n",
    "A minimum requirement for using topup for correcting distortions is that two spin-echo (SE) EPI images with different PE-directions have been acquired. The best is to acquire them with opposing PE-directions (i.e. A→P AND P→A or L→R AND R→L). An SE-EPI image is the same as a b=0 image acquired as a part of a diffusion protocol. Just as for fieldmaps, this pair must be acquired at the same occasion as the full diffusion protocol and the subject must not leave the scanner in between and no re-shimming can be done.\n",
    "\n",
    "From the denoised and GIbbs corrected files, choose a volume without diffusion weighting (e.g. the first volume). You can extract this as a standalone 3D image and call the extracted files nodif_AP/PA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the original dwi data ap and pa\n",
    "\n",
    "#phase encoding direction AP\n",
    "dwi_ap_data, dwi_ap_affine = load_nifti(f\"{dwi_path}/{dwi_ap_file}\")\n",
    "\n",
    "#phase encoding direction PA\n",
    "dwi_pa_data, dwi_pa_affine = load_nifti(f\"{dwi_path}/{dwi_pa_file}\")\n",
    "\n",
    "#extract the b0 images (first imaging volume) for both phase encoding directions\n",
    "nodif_ap = dwi_ap_data[:,:,:,0]\n",
    "nodif_pa = dwi_pa_data[:,:,:]\n",
    "\n",
    "#plot the slice 25 for each PE direction\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 6),\n",
    "                        subplot_kw={'xticks': [], 'yticks': []})\n",
    "\n",
    "ax.flat[0].imshow(nodif_ap[:, :, 25].T, cmap='gray',  interpolation='none' , origin='lower')\n",
    "ax.flat[0].set_title('b0 image AP direction')\n",
    "ax.flat[1].imshow(nodif_pa[:, :, 25].T, cmap='gray', interpolation='none', origin='lower')\n",
    "ax.flat[1].set_title('b0 image PA direction')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that regions that are squashed in the AP data appear elongated in the PA data and vice versa. Unsurprisingly the areas that were very obviously distorted when viewed in the nodif_ap image change a lot when you comapare them to the nodif_pa image. We will correct these distortions by combining the two b=0 images using the TOPUP tool. The next step is to merge the nodiff_ap and nodiff_pa files along the 4th 'timeseries' axis. Call the merged image ap_pa_b0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concatenate the data along the 4th dimension\n",
    "ap_pa_b0 = np.stack((nodif_ap, nodif_pa), axis=-1)\n",
    "\n",
    "#save the concatenated data\n",
    "save_nifti(f\"{out_dir}/preprocessing/sub-{sub}/ap_pa_b0.nii.gz\", ap_pa_b0, dwi_ap_affine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then create a text file that contains the information with the PE direction, the sign of the AP and PA volumes and some timing information obtained by the acquisition. This is a text-file called acqparams.txt that contains the lines:\n",
    "\n",
    "0 -1 0 0.0266003<br>\n",
    "0  1 0 0.0266003\n",
    "\n",
    "The first three elements of each line comprise a vector that specifies the direction of the phase encoding. The non-zero number in the second column means that is along the y-direction. A -1 means that k-space was traversed Anterior→Posterior and a 1 that it was traversed Posterior→Anterior. The final column specifies the \"total readout time\", which is the time (in seconds) between the collection of the centre of the first echo and the centre of the last echo. In the FAQ section of the online help for topup there are instructions for how to find this information for Siemens scanners (https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/topup/Faq). The file should contain as many entries as there are volumes in the image file that is passed to topup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check whether the acqparams.txt file exists and create it if it doesn't\n",
    "acq_file_path = f\"{out_dir}/preprocessing/sub-{sub}/acqparams.txt\"\n",
    "\n",
    "if not os.path.exists(acq_file_path):\n",
    "\n",
    "    #create the acqparams.txt file\n",
    "\n",
    "    lines = [\n",
    "        \"0 -1 0 0.0266003\\n\",\n",
    "        \"0  1 0 0.0266003\\n\"\n",
    "    ]\n",
    "\n",
    "    # Open the file in write mode and write the lines\n",
    "    with open(acq_file_path, 'w') as file:\n",
    "        file.writelines(lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to run topup which we will do using the python subprocess module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "#check whether the topup output file existes, and if not run topup\n",
    "topup_file_path = f\"{out_dir}/preprocessing/sub-{sub}/topup_ap_pa_b0_corrected.nii.gz\"\n",
    "\n",
    "if not os.path.exists(topup_file_path):\n",
    "\n",
    "    # Define the command execute topup\n",
    "    def run_topup(config_file, input_file, output_base, acq_params_file):\n",
    "\n",
    "        command = (\n",
    "            f'topup --config={config_file} '\n",
    "            f'--datain={acq_params_file} '\n",
    "            f'--imain={input_file} '\n",
    "            f'--out={output_base} '\n",
    "            f'--iout={output_base}_corrected '\n",
    "            f'--fout={output_base}_field '\n",
    "            f'--logout={output_base}_log.txt'\n",
    "        )\n",
    "\n",
    "        # Execute the command\n",
    "        try:\n",
    "            result = subprocess.run(command, shell=True, check=True, text=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "            print(\"TOPUP completed successfully.\")\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            print(\"Output:\\n\", e.stdout)\n",
    "            print(\"Errors:\\n\", e.stderr)\n",
    "\n",
    "\n",
    "    # Define paths to the relevant files\n",
    "    config_file = 'b02b0.cnf'\n",
    "    input_file_topup = f\"{out_dir}/preprocessing/sub-{sub}/ap_pa_b0.nii.gz\"\n",
    "    output_base_topup = f\"{out_dir}/preprocessing/sub-{sub}/topup_ap_pa_b0\"\n",
    "    acq_params_file = f\"{out_dir}/preprocessing/sub-{sub}/acqparams.txt\"\n",
    "\n",
    "\n",
    "    # Run TOPUP\n",
    "    run_topup(config_file, input_file_topup, output_base_topup, acq_params_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This command may take a long time to run, depending on the size of the dataset. \n",
    "\n",
    "There are four result files. topup_ap_pa_b0_fieldcoef.nii.gz contains information about the off-resonance field and topup_ap_pa_b0_movpar.txt specifies any movement between nodif_ap and nodif_pa. To visualise the results, we can use FSL's viewer FSLeyes.\n",
    "\n",
    "Open FSLeyes and load topup_AP_PA_b0_fieldcoef.nii.gz. It looks like a low resolution fieldmap, and it contains the spline coefficients for the field that TOPUP has estimated. Close FSLeyes and re-open it, but this time take a look at the actual field (topup_AP_PA_b0_fout). Moreover, to check that TOPUP has done its job properly, load topup_AP_PA_b0_iout and compare its two volumes to those we provided as input (AP_PA_b0.nii.gz).\n",
    "\n",
    "For a quick inspection of the corrected b0 volumes, you can run the code below. You can see that the sharp distortions in frontal regions are no longer present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load topup corrected data\n",
    "topup_data, topup_affine = load_nifti(f\"{out_dir}/preprocessing/sub-{sub}/topup_ap_pa_b0_corrected.nii.gz\")\n",
    "\n",
    "#plot the slice 25 for each PE direction\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 6),\n",
    "                        subplot_kw={'xticks': [], 'yticks': []})\n",
    "\n",
    "ax.flat[0].imshow(topup_data[:, :, 25, 0].T, cmap='gray',  interpolation='none' , origin='lower')\n",
    "ax.flat[0].set_title('corrected b0 image AP direction')\n",
    "ax.flat[1].imshow(topup_data[:, :, 25, 1].T, cmap='gray', interpolation='none', origin='lower')\n",
    "ax.flat[1].set_title('Corrected b0 image PA direction')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## EDDY - Correcting for Eddy Currents\n",
    "\n",
    "Again, the state-of-the-art tool for this step is part of the FSL software. EDDY performs eddy current and head movement correction simultaneously, and it also takes into account the output from TOPUP.\n",
    "\n",
    "FSL wiki: https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/eddy \n",
    "\n",
    "The first step is to generate a brain mask using the TOPUP corrected b0 images, starting by computing the average image of the corrected b0 volumes and naming the output file hifi_nodif. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#average the two corrected b0 images\n",
    "hifi_nodif = np.mean(topup_data, axis=3)\n",
    "\n",
    "#save the average b0 image\n",
    "save_nifti(f\"{out_dir}/preprocessing/sub-{sub}/hifi_nodif.nii.gz\", hifi_nodif, topup_affine)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we create a binary brain mask using the averaged b0 and name the output file hifi_nodif_brain. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dipy.segment.mask import median_otsu\n",
    "\n",
    "#create a binary brain mask\n",
    "hifi_nodif_brain, hifi_nodif_brain_mask = median_otsu(hifi_nodif, median_radius=4, numpass=4)\n",
    "\n",
    "#save the brain mask\n",
    "save_nifti(f\"{out_dir}/preprocessing/sub-{sub}/hifi_nodif_brain.nii.gz\", hifi_nodif_brain.astype(np.float32), topup_affine)\n",
    "save_nifti(f\"{out_dir}/preprocessing/sub-{sub}/hifi_nodif_brain_mask.nii.gz\", hifi_nodif_brain_mask.astype(np.float32), topup_affine)\n",
    "\n",
    "\n",
    "#plot the mid slice for the original and brain masked data\n",
    "fig, ax = plt.subplots(1, 3, figsize=(16, 6),\n",
    "                        subplot_kw={'xticks': [], 'yticks': []})\n",
    "\n",
    "ax.flat[0].imshow(hifi_nodif[:, :, mid_slice].T, cmap='gray',  interpolation='none' , origin='lower')\n",
    "ax.flat[0].set_title('Average corrected b0 image')\n",
    "ax.flat[1].imshow(hifi_nodif_brain[:, :, mid_slice].T, cmap='gray', interpolation='none', origin='lower')\n",
    "ax.flat[1].set_title('Brain masked b0 image')\n",
    "ax.flat[2].imshow(hifi_nodif_brain_mask[:, :, mid_slice].T, cmap='gray', interpolation='none', origin='lower')\n",
    "ax.flat[2].set_title('Binary brain mask')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to create the index.txt file which contains a column of ones, one for each volume in the dwi data, specifying that all volume were acquired with the parameters described by the first row in acqparams.txt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check whether the aindex.txt file exists and create it if it doesn't\n",
    "index_file_path = f\"{out_dir}/preprocessing/sub-{sub}/index.txt\"\n",
    "\n",
    "if not os.path.exists(index_file_path):\n",
    "\n",
    "    # Initialize an empty string\n",
    "    indx = \"\"\n",
    "\n",
    "    # Loop from 1 to the number of volumes in nogibbs_ap with step 1\n",
    "    for i in range(1, dwi_ap_data.shape[3]+1):\n",
    "        indx += \" 1\"  # Append \" 1\" to the string indx\n",
    "\n",
    "    # Write indx to a file named index.txt\n",
    "    with open(index_file_path, \"w\") as f:\n",
    "        f.write(indx.strip())  # Strip leading/trailing whitespace and write to file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to run eddy, using the subprocesses module again. As EDDY performs a simultaneous registration of all volumes in the dataset, it is quite memory and CPU hungry. Therefore this step will take a very long time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check whether the eddy unwarped file exists and if not run eddy\n",
    "eddy_file_path = f\"{out_dir}/preprocessing/sub-{sub}/eddy_unwarped_images.nii.gz\"\n",
    "\n",
    "if not os.path.exists(eddy_file_path):\n",
    "\n",
    "    #create an acqparams file for the eddy command including only the first line, given that only AP data will be passed to eddy\n",
    "    acq_eddy_file_path = f\"{out_dir}/preprocessing/sub-{sub}/acqparams_eddy.txt\"\n",
    "\n",
    "    #create the acqparams_eddy.txt file\n",
    "    line = [\n",
    "        \"0 -1 0 0.0266003\\n\"\n",
    "    ]\n",
    "\n",
    "    # Open the file in write mode and write the lines\n",
    "    with open(acq_eddy_file_path, 'w') as file:\n",
    "        file.writelines(line)\n",
    "\n",
    "    # Define the command to execute eddy\n",
    "    def run_eddy(input_file, mask_file, acq_params_file, index_file, bvecs_file, bvals_file, output_base_topup, output_base_eddy):\n",
    "\n",
    "        #command to run eddy \n",
    "        command = (\n",
    "            f'eddy --imain={input_file} '\n",
    "            f'--mask={mask_file} ' \n",
    "            f'--index={index_file} '\n",
    "            f'--acqp={acq_params_file} '\n",
    "            f'--bvecs={bvecs_file} '\n",
    "            f'--bvals={bvals_file} '\n",
    "            f'--fwhm=0 '\n",
    "            f'--topup={output_base_topup} '\n",
    "            f'--flm=quadratic '\n",
    "            f'--out={output_base_eddy}'\n",
    "        )\n",
    "\n",
    "        # Execute the command\n",
    "        try:\n",
    "            result = subprocess.run(command, shell=True, check=True, text=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "            print(\"EDDY completed successfully.\")\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            print(\"Output:\\n\", e.stdout)\n",
    "            print(\"Errors:\\n\", e.stderr)\n",
    "\n",
    "\n",
    "    # Define paths to the relevant files\n",
    "    input_file_eddy =  f\"{out_dir}/preprocessing/sub-{sub}/nogibbs_ap_mppca.nii.gz\"\n",
    "    acq_params_file = f\"{out_dir}/preprocessing/sub-{sub}/acqparams.txt\"\n",
    "    mask_file = f\"{out_dir}/preprocessing/sub-{sub}/hifi_nodif_brain_mask.nii.gz\"\n",
    "    index_file = f\"{out_dir}/preprocessing/sub-{sub}/index.txt\"\n",
    "    bvecs_file = f\"{dwi_path}/{dwi_ap_bvec}\"\n",
    "    bvals_file = f\"{dwi_path}/{dwi_ap_bval}\"\n",
    "    output_base_topup = f\"{out_dir}/preprocessing/sub-{sub}/topup_ap_pa_b0\"\n",
    "    output_base_eddy = f\"{out_dir}/preprocessing/sub-{sub}/eddy_unwarped_images\"\n",
    "\n",
    "\n",
    "    # Run EDDY\n",
    "    run_eddy(input_file_eddy, mask_file, acq_params_file, index_file, bvecs_file, bvals_file, output_base_topup, output_base_eddy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will find that eddy has produced three output files: eddy_unwarped_images.nii.gz, eddy_unwarped_images.rotated_bvecs and eddy_unwarped_images.eddy_parameters. The former of those is the \"main result\" and contains the data corrected for susceptibility, eddy currents and subject movements. \n",
    "\n",
    "This concludes the pre-processing steps and we are now ready for model fitting, which we will cover in Tutorial 3. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quality Control\n",
    "\n",
    "## EDDY QC\n",
    "\n",
    "As we have seen, dMRI data can be affected by many hardware or subject-specific artefacts. If undetected, these artefacts can bias downstream analysis. Quality control is therefore very important - always look at your data! In large population studies, manual quality control may not be practical. \n",
    "\n",
    "An FSL tool called eddy_quad provides automatic quality control at both the single subject and group level. For more info see https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/eddyqc.\n",
    "\n",
    "For each subject, eddy_quad will generate a pdf file with a data quality report, including information about subject movement, outliers, signal-to-noise ratio, amongst other metrics.\n",
    "\n",
    "![Example of eddy_quad output](eddy_quad_pdf.png)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check whether the eddy qc folder exists and if not run eddy qc\n",
    "qc_file_path = f\"{out_dir}/preprocessing/sub-{sub}/eddy_unwarped_images.qc\"\n",
    "\n",
    "if not os.path.exists(qc_file_path):\n",
    "   \n",
    "    # Define the command to execute eddy qc\n",
    "    def run_eddy_quad(input_file, mask_file, acq_params_file, index_file, bvals_file):\n",
    "\n",
    "        #command to run eddy \n",
    "        command = (\n",
    "            f'eddy_quad {input_file} '\n",
    "            f'-m {mask_file} ' \n",
    "            f'-idx {index_file} '\n",
    "            f'-par {acq_params_file} '\n",
    "            f'-b {bvals_file}'\n",
    "        )\n",
    "\n",
    "        # Execute the command\n",
    "        try:\n",
    "            result = subprocess.run(command, shell=True, check=True, text=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "            print(\"EDDY QUAD completed successfully.\")\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            print(\"Output:\\n\", e.stdout)\n",
    "            print(\"Errors:\\n\", e.stderr)\n",
    "\n",
    "\n",
    "    # Define paths to the relevant files\n",
    "    input_file_eddy_qc = f\"{out_dir}/preprocessing/sub-{sub}/eddy_unwarped_images\"\n",
    "    acq_params_file = f\"{out_dir}/preprocessing/sub-{sub}/acqparams_eddy.txt\"\n",
    "    mask_file = f\"{out_dir}/preprocessing/sub-{sub}/hifi_nodif_brain_mask.nii.gz\"\n",
    "    index_file = f\"{out_dir}/preprocessing/sub-{sub}/index.txt\"\n",
    "    bvals_file = f\"{dwi_path}/{dwi_ap_bval}\"\n",
    "    \n",
    "    # Run EDDY\n",
    "    run_eddy_quad(input_file_eddy_qc, mask_file, acq_params_file, index_file, bvals_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quality control can also be performed at the group level, using the eddy_squad command. This command reads all the single subject outputs from eddy_quad, generates study-wise reports and can optionally update single subject reports, indicating how the subject’s dataset compares to other data, using a ‘traffic light’ system (see below and example of an updated QC report). Lastly, eddy_squad also allows to report QC indices based on user-provided variables.\n",
    "\n",
    "![Example of eddy_squad output with 'traffic light' system](eddy_squad_pdf.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
