{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DTI Tractography\n",
    "\n",
    "Tractography is a 3D modeling technique used to visualize the white matter tracts within the brain. It leverages data from diffusion-weighted MRI to map out the white matter pathways, providing insights into the brain's connectivity and structural organization. \n",
    "\n",
    "In this tutorial we will focus on tractography based on the DTI model. The movement of water molecules tends to be more restricted along the direction of nerve fibers in white matter, and the DTI model can be used to identify the primary direction of diffusion.\n",
    "\n",
    "## Key Concepts in DTI Tractography\n",
    "\n",
    "1. Diffusion Tensor Imaging (DTI):\n",
    "\n",
    "    * Diffusion Weighted Imaging (DWI): DWI captures the diffusion of water molecules in different directions. In white matter, water diffusion is anisotropic (direction-dependent), which DTI exploits to model fiber orientation.\n",
    "\n",
    "    * Tensor Calculation: A tensor is computed for each voxel, describing the direction and magnitude of diffusion. The primary eigenvector of the tensor indicates the dominant direction of water diffusion, aligning with the direction of nerve fibers.\n",
    "\n",
    "2. Fiber Tracking:\n",
    "    \n",
    "    * Seed Points: Tractography algorithms start from seed points, typically placed in regions of interest within the brain. \n",
    "\n",
    "    * Tracking Algorithm: A method for propagating the streamlines. There are two main types of tracking algorithms:\n",
    "\n",
    "        * Deterministic Tractography: Follows the principal diffusion direction voxel by voxel, creating a single streamline per seed point.\n",
    "        \n",
    "        * Probabilistic Tractography: Accounts for uncertainty in fiber direction, generating multiple potential pathways from each seed point.\n",
    "\n",
    "    * Stopping criteria: a set of criteria to determine when streamline propagation should terminate. \n",
    "\n",
    "\n",
    "##  DTI Deterministic Tractography\n",
    "\n",
    "This tutorial will show how to create a tractography reconstruction from a diffusion MRI dataset (also know as tractogram), using the DTI model and deterministic tractography. and it will include examples from https://workshop.dipy.org/documentation/1.7.0/examples_built/. This procedure is called deterministic because if you repeat the exact steps below you will always get exactly the same set of streamlines. In the next tutorial we will discuss how this differs from probabilistic tractography. \n",
    "\n",
    "Firstly, we will load the pre-processed diffusion MRI data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load general modules\n",
    "import os\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "\n",
    "#load dipy modules\n",
    "from dipy.core.gradients import gradient_table\n",
    "from dipy.io.gradients import read_bvals_bvecs\n",
    "from dipy.io.image import load_nifti, save_nifti\n",
    "\n",
    "#load modules for visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#define the paths to the data\n",
    "scripts_dir = os.getcwd()\n",
    "bids_dir = \"../data/bids\"\n",
    "out_dir = \"../data/derivatives\"\n",
    "\n",
    "#subject code to be used in this example\n",
    "sub='01'\n",
    "\n",
    "#load the pre-processed data\n",
    "data_preproc, affine, data_preproc_img = load_nifti(f\"{out_dir}/preprocessing/sub-{sub}/eddy_unwarped_images.nii.gz\", return_img=True)\n",
    "\n",
    "#load the bvals and bvecs\n",
    "bvals, bvecs = read_bvals_bvecs(f\"{bids_dir}/sub-{sub}/dwi/sub-{sub}_acq-AP_dwi.bval\", f\"{out_dir}/preprocessing/sub-{sub}/eddy_unwarped_images.eddy_rotated_bvecs\")\n",
    "\n",
    "#select data for DTI model fitting\n",
    "#create a mask bo b-values less than 1300 s/mm2\n",
    "bval_mask = bvals < 1300\n",
    "\n",
    "#select the data for DTI model fitting\n",
    "data_for_dti = data_preproc[..., bval_mask]\n",
    "\n",
    "bvals_for_dti = bvals[bval_mask]\n",
    "bvecs_for_dti = bvecs[bval_mask, :]\n",
    "\n",
    "#load the gradient table\n",
    "gtab_for_dti = gradient_table(bvals_for_dti, bvecs_for_dti)\n",
    "\n",
    "\n",
    "#load the binary brain mask\n",
    "brain_mask, affine_mask = load_nifti(f\"{out_dir}/preprocessing/sub-{sub}/hifi_nodif_brain_mask.nii.gz\")\n",
    "masked_data = data_for_dti * brain_mask[..., np.newaxis]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Fit the DTI model to the data, and define a white matter mask by thresholding the FA map\n",
    "\n",
    "Here we simply follow the same steps already covere in Tutorial 3 (Model Fitting)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the TensorModel from dipy\n",
    "from dipy.reconst.dti import TensorModel\n",
    "\n",
    "#fit the DTI model\n",
    "dtimodel = TensorModel(gtab_for_dti)\n",
    "dtifit = dtimodel.fit(data_for_dti, mask=brain_mask) \n",
    "\n",
    "#create a white matter mask by thresholding the FA map\n",
    "fa = dtifit.fa\n",
    "fa_mask = fa > 0.2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Estimate the principal direction of diffusion from the DTI model\n",
    "\n",
    "For this we will use dipy's function peaks_from_model. This function provides a general strategy to estimate diffusion directions and it can be applied to different diffusion MRI reconstruction models. The function peaks_from_model requires a variable containing discrete directions for evaluation - this and other input parameters will be explained in more detail later on. For this example we simply load a default set of discrete directions available in dipy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dipy.direction import peaks_from_model\n",
    "from dipy.data import default_sphere\n",
    "\n",
    "dti_peaks = peaks_from_model(dtimodel, masked_data, default_sphere,\n",
    "                             relative_peak_threshold=.8,\n",
    "                             min_separation_angle=45,\n",
    "                             mask=fa_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For quality control, we can visualise the estimated direction field using the fury python package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cognestic/miniconda3/envs/mri/lib/python3.11/site-packages/IPython/core/interactiveshell.py:3577: UserWarning: We'll no longer accept the way you call the record function in future versions of FURY.\n",
      "\n",
      "Here's how to call the Function record: record(scene='value', cam_pos='value', cam_focal='value', cam_view='value', out_path='value', path_numbering='value', n_frames='value', az_ang='value', magnification='value', size='value', reset_camera='value', screen_clip='value', stereo='value', verbose='value')\n",
      "\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "from dipy.viz import window, actor, has_fury\n",
    "\n",
    "if has_fury:\n",
    "    scene = window.Scene()\n",
    "    scene.add(actor.peak_slicer(dti_peaks.peak_dirs,\n",
    "                               #dti_peaks.peak_values,\n",
    "                               colors=None))\n",
    "\n",
    "    window.record(scene, out_path=f'{out_dir}/DTI/sub-{sub}/dti_direction_field.png', size=(900, 900))\n",
    "    window.show(scene, size=(800, 800))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Define the seeds where streamline propagation will start\n",
    "\n",
    "In Dipy, the seeds for tracking are established using the seeds_from_mask function from dipy.tracking.utils. In this example, a 2 × 2 × 2 grid of seeds is placed in each voxel within a sagittal slice of the corpus callosum, using a pre-defined mask. The voxels to be seeded are determined by the 'seed_mask' input, which here consists of the voxels labeled with the value 1 in the \"CC_mask.nii.gz\" file, indicating voxels in a sagittal slice of the corpus callosum. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dipy.tracking import utils\n",
    "\n",
    "#load corpus callosum mask\n",
    "cc_mask, affine_cc = load_nifti(f\"{out_dir}/DTI/sub-{sub}/CC_mask.nii.gz\")\n",
    "\n",
    "seed_mask = (cc_mask == 1)\n",
    "seeds = utils.seeds_from_mask(seed_mask, affine_cc, density=[2, 2, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Defining stoping criteria\n",
    "\n",
    "\n",
    "In this example, a streamline will continue to propgate until it reaches a voxel with FA lower than 0.2. We will use the dipy function ThresholdStoppingCriterion to define this stopping criterion area. You can find an extensive review of the various options for stopping criteria for tractography here:\n",
    "\n",
    "https://workshop.dipy.org/documentation/1.7.0/examples_built/13_fiber_tracking/tracking_stopping_criterion/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dipy.tracking.stopping_criterion import ThresholdStoppingCriterion\n",
    "\n",
    "stopping_criterion = ThresholdStoppingCriterion(fa, 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Propagating the streamlines\n",
    "\n",
    "We now have everything we need to start generating streamlines. In Dipy, this process requires initialization. To do this, we use the LocalTracking function from dipy.tracking.local_tracking. The streamlines themselves will then be generated using the Streamlines function from dipy.tracking.streamline:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dipy.tracking.local_tracking import LocalTracking\n",
    "from dipy.tracking.streamline import Streamlines\n",
    "\n",
    "#initialize the streamlines generator\n",
    "streamlines_generator = LocalTracking(dti_peaks, stopping_criterion, seeds,\n",
    "                                      affine=affine, step_size=0.5)\n",
    "\n",
    "#generate the streamlines\n",
    "streamlines = Streamlines(streamlines_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These steps have created a deterministic set of streamlines from the principal diffusion direction estimated using the Diffusion Tensor model. \n",
    "\n",
    "Finally, we save the streamlines as a Trackvis file so it can be loaded into other software for visualization or further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dipy.io.stateful_tractogram import Space, StatefulTractogram\n",
    "from dipy.io.streamline import save_trk\n",
    "\n",
    "sft = StatefulTractogram(streamlines, data_preproc_img, Space.RASMM)\n",
    "save_trk(sft, f\"{out_dir}/DTI/sub-{sub}/dti_CC_deterministic_tract.trk\", streamlines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output can be visualised with the fury package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cognestic/miniconda3/envs/mri/lib/python3.11/site-packages/IPython/core/interactiveshell.py:3577: UserWarning: We'll no longer accept the way you call the line function in future versions of FURY.\n",
      "\n",
      "Here's how to call the Function line: line(lines_value, colors='value', opacity='value', linewidth='value', spline_subdiv='value', lod='value', lod_points='value', lod_points_size='value', lookup_colormap='value', depth_cue='value', fake_tube='value')\n",
      "\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "from dipy.viz import colormap\n",
    "\n",
    "if has_fury:\n",
    "    # Prepare the display objects.\n",
    "    color = colormap.line_colors(streamlines)\n",
    "\n",
    "    streamlines_actor = actor.line(streamlines,\n",
    "                                   colormap.line_colors(streamlines))\n",
    "\n",
    "    # Create the 3D display.\n",
    "    scene = window.Scene()\n",
    "    scene.add(streamlines_actor)\n",
    "\n",
    "    # Save still images for this static example. Or for interactivity use\n",
    "    window.record(scene, out_path=f'{out_dir}/DTI/sub-{sub}/dti_tractogram_det.png', size=(800, 800))\n",
    "    window.show(scene)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises\n",
    "\n",
    "1. In dipy, the total number of streamlines generated is determined by the number of seeds placed per voxel. This is controlled by the density parameter within utils.seeds_from_mask. In the example in this tutorial we used a 2x2x2 grid of seeds, i.e., 8 seeds per voxel. Try different seed densities and evaluate the impact of this parameter on the resulting tractogram.  \n",
    "\n",
    "2. Another important parameter is the the FA treshold we set as the stopping criteria. Try different thresholds and evaluate the impact of this parameter on the resulting tractogram.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
