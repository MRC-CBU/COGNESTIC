{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group Analysis of Diffusion MRI Data using Tract Base Spatial Statistics (TBSS)\n",
    "\n",
    "FSLwiki: https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/TBSS. \n",
    "\n",
    "So far, we have worked through the steps required to pre-process a typical diffusion-weighted dataset, followed by model fitting. Next, we will focus on running TBSS to compare FA values between two groups of participants.\n",
    "\n",
    "For this tutorial we will use a small dataset â€“ 10 young pariticipants in their 20s, and 10 older participants in their 70s. We will attempt to find whether there are any FA differences between the two groups.\n",
    "\n",
    "FA maps have already been computed for all participants, using the pre-rpocessing and model fitting steps discussed in previous tutorials.\n",
    "\n",
    "TBSS consists of four steps, followed by statistical inference using non-parametric testing. Before we get started, lets first check the data. We will do this by running and FSL command, slicesdir, which generate an html file displaying a few slices for each of the FA maps, allowing for a quick inspection and quality control of the data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import general modules\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "#set up paths\n",
    "scripts_dir = \"/home/cognestic/COGNESTIC/05_DWI/notebooks\"\n",
    "tbss_dir = \"/home/cognestic/COGNESTIC/05_DWI//data/GroupAnalysis/tbss\"\n",
    "\n",
    "print(tbss_dir)\n",
    "\n",
    "#check if the origdata folder exists within the tbss directory, which would suggest that the tbss_1_preproc script has been run \n",
    "orig_path = f\"{tbss_dir}/origdata\"\n",
    "\n",
    "if not os.path.exists(orig_path):\n",
    "    #list of files in tbss directory\n",
    "    for item in os.listdir(tbss_dir):\n",
    "        print(item)\n",
    "else:\n",
    "    #list the files in the origdata directory\n",
    "    for item in os.listdir(orig_path):\n",
    "        print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change to tbss directory\n",
    "os.chdir(tbss_dir)\n",
    "\n",
    "#check if a slicesdir folder exists within the tbss directory, which would suggest that the slicesdir command has been run\n",
    "slicesdir_path = f\"{tbss_dir}/slicesdir\"\n",
    "\n",
    "#if slicesdir has not been run, run it to inspect the FA data\n",
    "if not os.path.exists(slicesdir_path):\n",
    "\n",
    "    #set up the command\n",
    "    command = \"slicesdir *.nii.gz\"\n",
    "\n",
    "    # Execute the command\n",
    "    try:\n",
    "        result = subprocess.run(command, shell=True, check=True, text=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "        html_file = [f for f in os.listdir(f\"{tbss_dir}/slicesdir\") if f.endswith('.html')]\n",
    "        print(f\"slicesdir completed successfully. To visualise the output, open the following link in your browser: http://{tbss_dir}/slicesdir/{html_file[0]}\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        print(\"Output:\\n\", e.stdout)\n",
    "        print(\"Errors:\\n\", e.stderr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 - TBSS pre-processing\n",
    "\n",
    "The first TBSS script, tbss_1_preproc, will erode your FA images slightly to remove brain-edge artifacts and zero the end slices (again to remove likely outliers from the diffusion tensor fitting).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run tbss_1_preproc\n",
    "\n",
    "#change to tbss directory\n",
    "os.chdir(tbss_dir)\n",
    "\n",
    "#check if the origdata folder exists within the tbss directory, which would suggest that the tbss_1_preproc script has been run \n",
    "orig_path = f\"{tbss_dir}/origdata\"\n",
    "\n",
    "#if the origdata folder does not exist, run tbss_1_preproc\n",
    "if not os.path.exists(orig_path):\n",
    "    \n",
    "    #set up the command\n",
    "    command = \"tbss_1_preproc *.nii.gz\"\n",
    "\n",
    "    # Execute the command\n",
    "    try:\n",
    "        result = subprocess.run(command, shell=True, check=True, text=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "        print('tbss_1_preproc completed successfully.')\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        print(\"Output:\\n\", e.stdout)\n",
    "        print(\"Errors:\\n\", e.stderr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOOK AT YOUR DATA\n",
    "\n",
    "Check the images created in the FA directory. The tbss_1_preproc script will have re-run slicesdir on the preprocessed FA maps - open this report (you can find it in FA/slicesdir/index.html) and compare it to the slicesdir report you created earlier.\n",
    "\n",
    "\n",
    "## Step 2 - Template registration\n",
    "\n",
    "The next TBSS script runs the nonlinear registration, aligning all the FA data across subjects. The recommended approach is to align every FA image to the FMRIB58_FA template. This process can take a long time, as each registration takes around 10 minutes. This can be sped up if you have access to a server running cluster software such as SGE (Sun Grid Engine). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run tbss_2_reg\n",
    "\n",
    "#change to tbss directory\n",
    "os.chdir(tbss_dir)\n",
    "\n",
    "#check if the target.nii.gz file exists within the tbss/FA directory, which would suggest that the tbss_2_reg script has been run \n",
    "target_file_path = f\"{tbss_dir}/FA/target.nii.gz\"\n",
    "\n",
    "#if the target file does not exist, run tbss_2_reg\n",
    "if not os.path.exists(target_file_path):\n",
    "\n",
    "    #set up the command\n",
    "    command = \"tbss_2_reg -T\"\n",
    "\n",
    "    # Execute the command\n",
    "    try:\n",
    "        result = subprocess.run(command, shell=True, check=True, text=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "        print('tbss_2_reg completed successfully.')\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        print(\"Output:\\n\", e.stdout)\n",
    "        print(\"Errors:\\n\", e.stderr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 - Post-registration processing\n",
    "\n",
    "The previous script (tbss_2_reg) only got as far as registering all subjects to the chosen template. The tbss_3_postreg script applies these registrations to take all subjects into 1x1x1mm standard space.\n",
    "\n",
    "This script also merges all of the subjects' standard space nonlinearly aligned images into a single 4D image file called all_FA, created in a new subdirectory called stats. The mean of all FA images is created, called mean_FA, and this is then fed into the FA skeletonisation program to create mean_FA_skeleton. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run tbss_3_postreg\n",
    "\n",
    "#change to tbss directory\n",
    "os.chdir(tbss_dir)\n",
    "\n",
    "#check if the mean_FA_skeleton.nii.gz file exists within the tbss/stats directory, which would suggest that the tbss_3_postreg script has been run \n",
    "ske_file_path = f\"{tbss_dir}/stats/mean_FA_skeleton.nii.gz\"\n",
    "\n",
    "#if the skeleton file does not exist, run tbss_3_postreg\n",
    "if not os.path.exists(ske_file_path):\n",
    "\n",
    "    #set up the command\n",
    "    command = \"tbss_3_postreg -S\"\n",
    "\n",
    "    # Execute the command\n",
    "    try:\n",
    "        result = subprocess.run(command, shell=True, check=True, text=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "        print('tbss_3_postreg completed successfully.')\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        print(\"Output:\\n\", e.stdout)\n",
    "        print(\"Errors:\\n\", e.stderr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the script has finished running, check that the mean FA image looks reasonable, and is well aligned with the MNI152 image: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import modules for visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from nilearn import plotting, image\n",
    "from nilearn.image import load_img\n",
    "\n",
    "#path to FSLDIR\n",
    "fsldir_path = os.environ.get('FSLDIR')\n",
    "\n",
    "# Load the images\n",
    "background_img = load_img(f\"{fsldir_path}/data/standard/MNI152_T1_1mm.nii.gz\")\n",
    "overlay_img = load_img(f\"{tbss_dir}/stats/mean_FA.nii.gz\")\n",
    "\n",
    "#theshold the mean FA image to show only values between 0.2 and 0.9 for display purposes\n",
    "data = overlay_img.get_fdata()\n",
    "thresholded_data = np.where((data >= 0.2) & (data <= 0.9), data, 0)\n",
    "\n",
    "# Create a new Nilearn image object with the thresholded data\n",
    "thresholded_img = image.new_img_like(overlay_img, thresholded_data)\n",
    "\n",
    "# Plotting the background image with the overlay\n",
    "display = plotting.plot_anat(background_img, display_mode='ortho')\n",
    "display.add_overlay(thresholded_img, cmap=plt.cm.hot, transparency=0.7)  # Using 'hot' colormap\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean FA image is indeed well aligned to standard space and corresponds to white matter in the MNI152 image. Next, we can look at the mean FA skeleton, overlaid on top of the mean FA image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the images\n",
    "background_img = load_img(f\"{tbss_dir}/stats/mean_FA.nii.gz\")\n",
    "overlay_img = load_img(f\"{tbss_dir}/stats/mean_FA_skeleton.nii.gz\")\n",
    "\n",
    "#theshold the mean skeleton FA image to show only values between 0.2 and 1 for display purposes\n",
    "data = overlay_img.get_fdata()\n",
    "thresholded_data = np.where((data >= 0.2) & (data <= 1), 1, 0)\n",
    "\n",
    "# Create a new Nilearn image object with the thresholded data\n",
    "thresholded_img = image.new_img_like(overlay_img, thresholded_data)\n",
    "\n",
    "# Plotting the background image with the overlay\n",
    "display = plotting.plot_anat(background_img, display_mode='ortho', interpolation='nearest')\n",
    "display.add_overlay(thresholded_img, cmap=plt.cm.ocean, transparency=0.7, interpolation='nearest')  # Using 'ocean' colormap to display the skeleton in green \n",
    "\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 - Projecting all pre-aligned FA data onto the skeleton\n",
    "\n",
    "The last TBSS script carries out the final steps necessary before you run the voxelwise cross-subject stats. It thresholds the mean FA skeleton image at the chosen threshold, typically 0.2. \n",
    "\n",
    "The thresholding creates a binary skeleton mask that defines the set of voxels used in all subsequent processing. \n",
    "\n",
    "Next a \"distance map\" is created from the skeleton mask. This is used in the projection of each subject's FA onto the skeleton; when searching outwards from a skeleton voxel for the local tract centre, the search only continues while the distance map values keep increasing - this means that the search knows to stop when it has got more than halfway between the starting skeleton point and another separate part of the skeleton.\n",
    "\n",
    "Finally, the script takes the 4D pre-aligned FA images in all_FA and, for each \"timepoint\" (subject ID), projects the FA data onto the mean FA skeleton. This results in a 4D image file containing the (projected) skeletonised FA data. It is this file that you will feed into voxelwise statistics in the next step. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run tbss_4_prestats\n",
    "\n",
    "#change to tbss directory\n",
    "os.chdir(tbss_dir)\n",
    "\n",
    "#check if the all_FA_skeletonised.nii.gz file exists within the tbss/stats directory, which would suggest that the tbss_4_prestats script has been run \n",
    "all_ske_file_path = f\"{tbss_dir}/stats/all_FA_skeletonised.nii.gz\"\n",
    "\n",
    "#if the skeletonised data does not exist, run tbss_4_prestats\n",
    "if not os.path.exists(all_ske_file_path):\n",
    "\n",
    "    #set up the command\n",
    "    command = \"tbss_4_prestats 0.2\"\n",
    "\n",
    "    # Execute the command\n",
    "    try:\n",
    "        result = subprocess.run(command, shell=True, check=True, text=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "        print('tbss_4_prestats completed successfully.')\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        print(\"Output:\\n\", e.stdout)\n",
    "        print(\"Errors:\\n\", e.stderr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5 - Voxelwise statistics on the skeletonised FA data\n",
    "\n",
    "The previous steps resulted in the 4D all_FA_skeletonised.nii.gz file. It is this that you now feed into voxelwise statistics, that, for example, tells you which FA skeleton voxels are significantly different between two groups of subjects.\n",
    "\n",
    "The recommended way of doing the stats is to use the randomise tool. For more detail see the Randomise manual https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/Randomise/UserGuide.\n",
    "\n",
    "Before running randomise you will need to generate design matrix and contrast files (e.g., design.mat and design.con). Since we are only interested in the comparison between the two groups, with no covariates, we will use the design_ttest2 command to generate simple design mtrix and contrast files.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change into the stats directory\n",
    "os.chdir(f\"{tbss_dir}/stats\")\n",
    "\n",
    "#creat the designa matrix and contrast files for comparing two groups of 10 pariticpants each \n",
    "command = f\"module load fsl; design_ttest2 design 10 10\"\n",
    "\n",
    "# Execute the command\n",
    "try:\n",
    "    result = subprocess.run(command, shell=True, check=True, text=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "    print('design_ttest2 completed successfully.')\n",
    "except subprocess.CalledProcessError as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "    print(\"Output:\\n\", e.stdout)\n",
    "    print(\"Errors:\\n\", e.stderr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This step creates two files named design.mat and design.con. You are now ready to run the stats using randomise. TBSS developers recommend you should use --T2 option for TFCE instead of cluster-based thresholding for correction of multiple comparisons. Typically you would run 5000 permutations, but in the interest of time we will run just 500:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change into the stats directory\n",
    "os.chdir(f\"{tbss_dir}/stats\")\n",
    "\n",
    "#check if the tbss_tfce_corrp_tstat1.nii.gz file exists within the tbss/stats directory, which would suggest that the randomise step has been run \n",
    "corrp_file_path = f\"{tbss_dir}/stats/tbss_tfce_corrp_tstat1.nii.gz\"\n",
    "\n",
    "#if the skeletonised data does not exist, run randomise\n",
    "if not os.path.exists(corrp_file_path):\n",
    "\n",
    "    #set up the command to run randomise with 500 permutations\n",
    "    command = (\n",
    "        f'randomise -i all_FA_skeletonised '\n",
    "        f'-o tbss '\n",
    "        f'-m mean_FA_skeleton_mask '\n",
    "        f'-d design.mat '\n",
    "        f'-t design.con '\n",
    "        f'-n 500 '\n",
    "        f'--T2 ' \n",
    "        f'-V'\n",
    "    )\n",
    "\n",
    "    # Execute the command\n",
    "    try:\n",
    "        result = subprocess.run(command, shell=True, check=True, text=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "        print('randomise completed successfully.')\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        print(\"Output:\\n\", e.stdout)\n",
    "        print(\"Errors:\\n\", e.stderr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contrast 1 gives the FA(old) > FA(young) test. The raw unthresholded tstat image is tbss_tstat1 and the corresponding (p-values corrected for multiple comparisons) cluster image is tbss_tfce_corrp_tstat1.\n",
    "\n",
    "Thresholding clusters at 0.95 (corresponding to thresholding the p-values at 0.05, because randomise outputs p-values as 1-p for convenience of display - so that higher values are more significant). The following shows the corrected significant values in red-yellow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the images\n",
    "background_img = load_img(f\"{fsldir_path}/data/standard/MNI152_T1_1mm.nii.gz\")\n",
    "overlay_img = load_img(f\"{tbss_dir}/stats/tbss_tfce_corrp_tstat1.nii.gz\")\n",
    "\n",
    "#theshold the significance map to show only values between 0.95 and 1 to keep only significant skeleton voxels\n",
    "data = overlay_img.get_fdata()\n",
    "thresholded_data = np.where((data >= 0.95) & (data <= 1), data, 0)\n",
    "\n",
    "# Create a new Nilearn image object with the thresholded data\n",
    "thresholded_img = image.new_img_like(overlay_img, thresholded_data)\n",
    "\n",
    "# Plotting the background image with the overlay\n",
    "display = plotting.plot_anat(background_img, display_mode='ortho')\n",
    "display.add_overlay(thresholded_img, cmap=plt.cm.hot, transparency=0.7)  # Using 'hot' colormap\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, there are no voxels in red or yellow. This is because there are no significant voxels for this comparison. This is not unexpected, since many studies have shown that FA generally decreases with age. \n",
    "\n",
    "Contrast 2 gives the FA(old) < FA(young) test, and the figure below shows the corrected significant values in green-blue:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the overlay image\n",
    "overlay_img = load_img(f\"{tbss_dir}/stats/tbss_tfce_corrp_tstat2.nii.gz\")\n",
    "\n",
    "#theshold the significance map to show only values between 0.95 and 1 to keep only significant skeleton voxels\n",
    "data = overlay_img.get_fdata()\n",
    "thresholded_data = np.where((data >= 0.95) & (data <= 1), data, 0)\n",
    "\n",
    "# Create a new Nilearn image object with the thresholded data\n",
    "thresholded_img = image.new_img_like(overlay_img, thresholded_data)\n",
    "\n",
    "# Plotting the background image with the overlay\n",
    "display = plotting.plot_anat(background_img, display_mode='ortho')\n",
    "display.add_overlay(thresholded_img, cmap=plt.cm.winter_r, transparency=0.7)  # Using 'winter' colormap\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our group analysis reveals widespread decline of FA with age, which is in line with previous reports in the Ageing literature. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise\n",
    "\n",
    "1. Investigate the impact of the skeleton threshold parameter specified in tbss_4_prestats."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
