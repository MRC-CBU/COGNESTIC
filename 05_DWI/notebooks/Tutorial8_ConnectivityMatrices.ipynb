{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Structural Connectivity Matrices\n",
    "\n",
    "This tutorial will give an introduction to the dipy tools which can be used to generate connectivity matrices for structural connectivity analyses. For more options please check the dipy tutorials online https://workshop.dipy.org/documentation/0.16.0./examples_built/streamline_tools/.\n",
    "\n",
    "The first step is to generate a set of streamlines. We will follow the same steps covered in the HARDI tractography tutorial to generate a whole brain tractogram using probabilistic CSD tractography. For this example we will use a sample dataset provided with dipy, the Stanford HARDI dataset which consists of a single subject’s diffusion, b-values and b-vectors, and some labels defined after freesurfer segmentation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load general modules\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage import binary_dilation\n",
    "\n",
    "#load the relevant dipy modules\n",
    "from dipy.core.gradients import gradient_table\n",
    "from dipy.data import get_fnames\n",
    "from dipy.io.gradients import read_bvals_bvecs\n",
    "from dipy.io.image import load_nifti_data, load_nifti, save_nifti\n",
    "from dipy.io.stateful_tractogram import Space, StatefulTractogram\n",
    "from dipy.io.streamline import save_trk\n",
    "from dipy.direction import peaks\n",
    "from dipy.reconst import shm\n",
    "from dipy.tracking import utils\n",
    "from dipy.reconst.csdeconv import auto_response_ssst\n",
    "from dipy.reconst.csdeconv import ConstrainedSphericalDeconvModel\n",
    "from dipy.tracking.local_tracking import LocalTracking\n",
    "from dipy.tracking.stopping_criterion import BinaryStoppingCriterion\n",
    "from dipy.tracking.streamline import Streamlines\n",
    "from dipy.direction import ProbabilisticDirectionGetter\n",
    "from dipy.data import get_sphere\n",
    "from dipy.viz import has_fury, window, actor, colormap\n",
    "from IPython.display import display, Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the Stanford HARDI dataset\n",
    "\n",
    "hardi_fname, hardi_bval_fname, hardi_bvec_fname = get_fnames('stanford_hardi')\n",
    "label_fname = get_fnames('stanford_labels')\n",
    "t1_fname = get_fnames('stanford_t1')\n",
    "\n",
    "data, affine, hardi_img = load_nifti(hardi_fname, return_img=True)\n",
    "labels = load_nifti_data(label_fname)\n",
    "t1_data = load_nifti_data(t1_fname)\n",
    "bvals, bvecs = read_bvals_bvecs(hardi_bval_fname, hardi_bvec_fname)\n",
    "gtab = gradient_table(bvals, bvecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This step will take several minutes to run \n",
    "\n",
    "#define a white matter mask using labels 1 and 2\n",
    "white_matter = binary_dilation((labels == 1) | (labels == 2))\n",
    "\n",
    "#estimate response function\n",
    "response, ratio = auto_response_ssst(gtab, data, roi_radii=10, fa_thr=0.7)\n",
    "\n",
    "#define and fit the CSD model to the data\n",
    "csd_model = ConstrainedSphericalDeconvModel(gtab, response, sh_order_max=6)\n",
    "csd_fit = csd_model.fit(data, mask=white_matter)\n",
    "\n",
    "# define the seeds and stopping criterion\n",
    "seeds = utils.seeds_from_mask(white_matter, affine, density=1)\n",
    "stopping_criterion = BinaryStoppingCriterion(white_matter)\n",
    "\n",
    "#load the directions evenly distributed on a sphere\n",
    "sphere = get_sphere('symmetric724')\n",
    "\n",
    "# define the PMF from the ODF\n",
    "fod = csd_fit.odf(sphere)\n",
    "pmf = fod.clip(min=0)\n",
    "\n",
    "# instanciate the probabilistic direction getter\n",
    "prob_dg = ProbabilisticDirectionGetter.from_pmf(pmf, max_angle=30.,\n",
    "                                                sphere=sphere)\n",
    "\n",
    "# initialise the streamlines generator\n",
    "streamline_generator_prob = LocalTracking(prob_dg, stopping_criterion, seeds,\n",
    "                                     affine, step_size=0.5)\n",
    "\n",
    "\n",
    "# generate the streamlines\n",
    "streamlines = Streamlines(streamline_generator_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using a target ROI (Region of Interest)\n",
    "\n",
    "The first of the tracking utilities we will cover in this tutorial is \"target\". This function takes a set of streamlines and a region of interest (ROI) and returns only those streamlines that pass though the ROI. The ROI should be an array such that the voxels that belong to the ROI are True and all other voxels are False (binary mask). \n",
    "\n",
    "This function can also exclude all the streamlines that pass though an ROI by setting the \"include\" flag to False. In this example we will target the streamlines of the corpus callosum. We will use a previously defined mask (a sagittal slice over the corpus callosum) and create two sets of streamlines, those that intersect with the ROI and those that don’t."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select a sagittal slice of the corpus callosum (label = 2)\n",
    "cc_slice = labels == 2\n",
    "\n",
    "#use the utils.target function to select the streamlines that pass through the CC slice\n",
    "cc_streamlines = utils.target(streamlines, affine, cc_slice)\n",
    "cc_streamlines = Streamlines(cc_streamlines)\n",
    "\n",
    "#select the streamlines that do not pass through the CC slice\n",
    "other_streamlines = utils.target(streamlines, affine, cc_slice,\n",
    "                                 include=False)\n",
    "other_streamlines = Streamlines(other_streamlines)\n",
    "\n",
    "#check that the number of streamlines is the same\n",
    "assert len(other_streamlines) + len(cc_streamlines) == len(streamlines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use dipy tools to visualise the two sets of tracts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualise the tractogram\n",
    "\n",
    "if has_fury:\n",
    "    # Prepare the display objects.\n",
    "    colors = colormap.line_colors(cc_streamlines)\n",
    "\n",
    "    # Updated actor.line call (explicit keyword argument for colors)\n",
    "    streamlines_actor = actor.line(cc_streamlines, colors=colors)\n",
    "\n",
    "    # Create the 3D display.\n",
    "    scene = window.Scene()\n",
    "    scene.add(streamlines_actor)\n",
    "\n",
    "    # Updated window.record call (explicit keyword arguments)\n",
    "    window.record(scene=scene,\n",
    "                  out_path='csd_tractogram_cc_target.png',\n",
    "                  size=(800, 800))\n",
    "\n",
    "    # Display the saved tractogram image\n",
    "    display(Image(filename='csd_tractogram_cc_target.png', width=600))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we might want to find out which regions of the brain are connected by these streamlines. To do this we can use the \"connectivity_matrix\" function. This function takes a set of streamlines and an array of labels as arguments. It returns the number of streamlines that start and end at each pair of labels and it can return the streamlines grouped by their endpoints. Notice that this function only considers the endpoints of each streamline.\n",
    "\n",
    "The set of labels can be defined in many ways, but one typical approach is to use the cortical parcellation from FreeSurfer. Because \"recon-all\" takes several hours, this step has already been performed for the Stanford HARDI dataset. \n",
    "\n",
    "The image aparc-reduced.nii.gz, which we load as labels_img, is a modified version of the label map aparc+aseg.mgz created by FreeSurfer. The corpus callosum region is a combination of the FreeSurfer labels 251-255. The remaining FreeSurfer labels were re-mapped and reduced so that they lie between 0 and 88. To see the FreeSurfer region, label and name, represented by each value, see label_info.txt in ~/.dipy/stanford_hardi.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select a slice to plot\n",
    "slice_z = labels[:, :, 30]\n",
    "\n",
    "# Plot the slice showing the labels\n",
    "plt.imshow(np.rot90(slice_z), cmap='inferno')\n",
    "plt.title('Stanford HARDI labels')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to create the connectivity matrix for the corpus callosum:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M, grouping = utils.connectivity_matrix(cc_streamlines, affine,\n",
    "                                        labels.astype(np.uint8),\n",
    "                                        return_mapping=True,\n",
    "                                        mapping_as_streamlines=True,\n",
    "                                        symmetric=True)\n",
    "M[:3, :] = 0\n",
    "M[:, :3] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally, we can display the connectivity matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.log1p(M), interpolation='nearest')\n",
    "#plt.savefig(\"connectivity.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
