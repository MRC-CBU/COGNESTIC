{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "756b0360",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<h1><span style=\"color:blue\">The BLUE exercise</span></h1>\n",
    "\n",
    "In this exercise, an experiment has been run to measure the brain response to oddly coloured fruit stimuli. Each item is either blue or pink, and is either an apple or a pear. The experiment has eight runs, with two conditions (estimated patterns) per run. The two factors have been balanced per run, and across the whole experiment, such that within each run one condition is blue and the other is pink, and one condition is apples and the the other is pears.\n",
    "\n",
    "Two binary classifications have been run for each of 40 subjects, using leave-one-run-out cross-validation. The first classification decodes colour, and accuracy is significantly above chance. The second classification decodes fruit type, and **accuracy is significantly *below* chance.**. \n",
    "\n",
    "***How is this possible?***\n",
    "\n",
    "***Change the analysis so that it no longer returns implausible below-chance accuracy.***\n",
    "\n",
    "How could the experiment have been better designed to avoid this issue in the first place?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e7ccad-6235-42c7-99dd-7cead1359d7a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Getting ready\n",
    "\n",
    "Import the packages we might need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9666db-c850-42d0-9473-c7f1d92c55c2",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np              # This lets python process matrices, like Matlab\n",
    "import matplotlib.pyplot as plt # This lets python plot graphs like Matlab\n",
    "import seaborn as sns           # This provides another popular set of plotting functions\n",
    "import scipy                    # This provides scientific capabilities like t-tests\n",
    "\n",
    "# scikit-learn is the major library for machine learning in Python:\n",
    "import sklearn as skl\n",
    "from sklearn import preprocessing # includes LabelEncoder, OneHotEncoder, StandardScaler...\n",
    "from sklearn import model_selection # includes StratifiedKFold, LeaveOneGroupOut...\n",
    "from sklearn import linear_model # includes LogisticRegression, RidgeClassifier...\n",
    "from sklearn import svm # includes SVC, NuSVC & LinearSCV...\n",
    "from sklearn import discriminant_analysis # includes LinearDiscriminantAnalysis\n",
    "from sklearn import metrics # includes roc_auc_score...\n",
    "from sklearn import pipeline # includes make_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45f5a53-9f2c-474a-b1cb-23c64d6700b4",
   "metadata": {},
   "source": [
    "Set the random number generator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce516c22-7aec-4bcf-b9a4-231b8b1d51dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6441d6-4241-4b4d-a8b0-100cad86d0ed",
   "metadata": {},
   "source": [
    "## Simulate some data from a 2 x 2 design:\n",
    "\n",
    "The factors are colour (blue, pink) and fruit (apple, pear).\n",
    "There are 8 runs, and each run has two patterns.\n",
    "The factors are counterbalanced so that the patterns in each run correpond to one sample of each colour, and one sample of each fruit.\n",
    "Across the whole experiment, there are equal numbers of patterns evoked by blue apples, blue pears, pink apples, and pink pairs (4 of each)\n",
    "I.e. in four runs the patterns correspond to \"blue apple\" and \"pink pear\"; in four runs the patterns correspond to \"pink apple\" and \"blue pear\"\n",
    "\n",
    "For simplicity we'll only consider 2 voxels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9d6759-ebd6-4f99-ad97-a217ab84199e",
   "metadata": {},
   "outputs": [],
   "source": [
    "npeople = 40 # number of participants\n",
    "\n",
    "nruns= 8 # number of runs\n",
    "\n",
    "# dict containing mean activation pattern in response to each stimulus attribute:\n",
    "mu = {\n",
    "    'blue': np.array([-1, 1]), \n",
    "    'pink': np.array([1, -1]), \n",
    "    'apple':np.array([1 , 1]),\n",
    "    'pear': np.array([1,  1]) \n",
    "}\n",
    "\n",
    "voxel_covariance = np.diag([1,1]) + 1 # voxel covariance: independent noise per voxel plus some covariance\n",
    "\n",
    "data = [] # list of pattern matrices (one per participant)\n",
    "\n",
    "for p in np.arange(npeople):\n",
    "    \n",
    "    data_per_run    = [] # list of pattern matrices     (one for each run)\n",
    "    colours_per_run = [] # list of colour label vectors (one for each run)\n",
    "    fruits_per_run  = [] # list of fruit  label vectors (one for each run)\n",
    "    for r in np.arange(nruns):\n",
    "        if np.mod(r,2) == 0: # stimulus pairs alternate across runs\n",
    "            colour1='blue'; fruit1='apple'\n",
    "            colour2='pink'; fruit2='pear'\n",
    "        else:\n",
    "            colour1='pink'; fruit1='apple'\n",
    "            colour2='blue'; fruit2='pear'\n",
    "        \n",
    "        colour_labels = [colour1] + [colour2];\n",
    "        fruit_labels  = [fruit1]  + [fruit2];\n",
    "        # sample activation pattern in response to each stimulus type:\n",
    "        pattern1 =  np.random.multivariate_normal(mu[colour1]+mu[fruit1], voxel_covariance, size=1)\n",
    "        pattern2 =  np.random.multivariate_normal(mu[colour2]+mu[fruit2], voxel_covariance, size=1)\n",
    "        data_matrix  =  np.concatenate((pattern1, pattern2))\n",
    "        \n",
    "        data_per_run.append   ( data_matrix ) \n",
    "        colours_per_run.append( colour_labels ) \n",
    "        fruits_per_run.append ( fruit_labels ) \n",
    "    \n",
    "    # concatenate runs for this participant\n",
    "    data.append( np.concatenate(data_per_run, axis = 0) )\n",
    "\n",
    "# same for all particiapnts:\n",
    "colours =     np.concatenate(colours_per_run, axis = 0) \n",
    "fruits =      np.concatenate(fruits_per_run,  axis = 0) \n",
    "run_indices = np.concatenate([[i] * 2 for i in range(nruns)]) \n",
    "print('Colour labels per pattern:', colours)\n",
    "print('\\nFruit labels per pattern:', fruits)\n",
    "print('\\nRun indices per pattern:', run_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8c0cbf-00d4-42f0-87cf-8d3967592f2d",
   "metadata": {},
   "source": [
    "\\\n",
    "Plot the data for the first two voxels of the first participant:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19de6a1-040f-43cd-95de-ed2a331e4a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.scatterplot(x = data[0][:,0], y = data[0][:,1], hue = colours, style = fruits, \n",
    "                     palette = ['b','m'], markers = ['o','^'], s = 80);\n",
    "ax.set_xlabel('voxel 1 activity', fontsize = 14);\n",
    "ax.set_ylabel('voxel 2 activity', fontsize = 14);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f598ee52-6536-4ed9-9afa-294df60ea189",
   "metadata": {},
   "source": [
    "\\\n",
    "Specify the pre-processing, classification pipeline, and leave-one-run-out cross-validation scheme:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2ee9de-5a63-456d-950f-8fd08e125969",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler = skl.preprocessing.StandardScaler()\n",
    "SVM    = skl.svm.LinearSVC(dual='auto')\n",
    "pipe   = skl.pipeline.make_pipeline(scaler, SVM)\n",
    "logo   = skl.model_selection.LeaveOneGroupOut()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b7d86b-0153-498f-89a7-0eb690280545",
   "metadata": {},
   "source": [
    "\\\n",
    "Classify colour for each participant:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2435b5b6-11f3-4165-b22e-5a8a9364cdb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "colour_accuracy = np.full(npeople, np.nan)\n",
    "for p in np.arange(npeople):\n",
    "    accuracy_per_fold = skl.model_selection.cross_val_score(pipe, data[p], colours, groups = run_indices, cv = logo, scoring = 'balanced_accuracy')\n",
    "    colour_accuracy[p] = np.mean(accuracy_per_fold)\n",
    "    #print(\"Participant \", p, \": Accuracy per fold: \", accuracy_per_fold, \"Mean accuracy (for random data):\", colour_accuracy[p])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a341c3-efb6-460e-ab0f-f5322b479ce0",
   "metadata": {},
   "source": [
    "\\\n",
    "Run a one-sample t-test across participants and find significant discrimination of colours:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007c8827-e3c5-4476-832e-3222b0050103",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = scipy.stats.ttest_1samp(colour_accuracy, 0.5, alternative = 'two-sided')\n",
    "print(\"Mean accuracy of colour classification across participants:\", np.mean(colour_accuracy))\n",
    "print(f't({result.df}) = {result.statistic:.2f}; p = {result.pvalue:.2e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a013fb9e-a8ae-4e4f-8141-0bafb5ed5d9a",
   "metadata": {},
   "source": [
    "\\\n",
    "Now classify fruit for each participant:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e47a61a-b311-4eca-b3e5-ffc93156db63",
   "metadata": {},
   "outputs": [],
   "source": [
    "fruit_accuracy = np.full(npeople, np.nan)\n",
    "for p in np.arange(npeople):\n",
    "    accuracy_per_fold = skl.model_selection.cross_val_score(pipe, data[p], fruits, groups = run_indices, cv = logo, scoring = 'balanced_accuracy')\n",
    "    fruit_accuracy[p] = np.mean(accuracy_per_fold)\n",
    "    #print(\"Participant \", p, \": Accuracy per fold: \", accuracy_per_fold, \"Mean accuracy (for random data):\", fruit_accuracy[p])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3042fb-311f-4f28-80bb-2ae25f1cb6bb",
   "metadata": {},
   "source": [
    "\\\n",
    "Run a one-sample t-test across participants and find **significantly *below chance* classification accuracy** for fruits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a828be-490f-4b75-8446-77564c7b884b",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = scipy.stats.ttest_1samp(fruit_accuracy, 0.5, alternative = 'two-sided')\n",
    "print(\"Mean accuracy of fruit classification across participants:\", np.mean(fruit_accuracy))\n",
    "print(f't({result.df}) = {result.statistic:.2f}; p = {result.pvalue:.2e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f30e9b-dce0-4ca3-9456-4f209f9e48fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.histplot(fruit_accuracy, element = 'step', alpha = 0.3, color = 'r')\n",
    "ax.set_xlabel('accuracy of fruit classification', fontsize = 14)\n",
    "ax.set_ylabel('count of participants',            fontsize = 14)\n",
    "lh = ax.axvline(0.5, color = 'k', label = 'chance')\n",
    "mh = ax.plot(np.mean(fruit_accuracy), 0, marker = 'o', color = 'r', markersize = 10, label = 'observed mean')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f777e4-cabd-4b5d-91af-088e2f622928",
   "metadata": {},
   "source": [
    "## Questions:\n",
    " - Significantly below-chance performance for leave-one-run-out cross-validation shouldn't be possible, right??\n",
    " - How has this happened?\n",
    " - Can you change the analysis to get a classification score that's no longer significantly below chance?\n",
    "\n",
    "## Hints:\n",
    "- Think carefully about how the stimulus features are counter-balanced across the experiment\n",
    "- Think about the choice of cross-validation partitions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061a0723-84f2-400a-a50c-cf21b106944a",
   "metadata": {},
   "source": [
    "## Explanation and possible solutions:\n",
    "\n",
    "The stimulus features are fully counter-balanced *across the whole experiment*, but they are *not counter-balanced per run*. This means that when *one* run is held out for testing, the training set is no longer balanced...\n",
    "\n",
    "\"But our scoring metric is 'balanced-accuracy,' so shouldn't it be insensitive to unbalanced samples?\"\n",
    "\n",
    "Well... in this example we need to consider not just the feature we're decoding, but the conjunction with the other feature it's paired with. And this conjunction has opposite imbalance for the train and test sets. Let's consider a fold where the test run contains the patterns \"blue apple\" and \"pink pear\". In the training runs, apples will more often be pink, and pears will more often be blue.\n",
    "\n",
    "Now, in this example there happens to be a true and strong pattern difference between blue and pink stimuli, but no real pattern difference between apple and pear stimuli. So, the classifier is able to decode colour easily. But when it learns to classify fruits, it learns that apples are associated with the pink response pattern and pears are associated with the blue response pattern. So when it is tested on a blue apple, it tends to wrongly guess pear, and when presented with a pink pear it tends to wrongly guess apple.\n",
    "\n",
    "When designing an experiment, the safest way to avoid these sorts of problems is to ensure that all features and their conjunctions are fully counter-balanced within each run. But this might not always be possible, or the problem might be discovered after the data have already been acquired. In this example, a solution is to adjust the partition scheme so that each training set is fully counter-balanced (i.e. for features and their conjunctions). This experiment was designed such that each pair of two consecutive runs *do* counter-balance the features, so that each fruit is equally likely to be each colour. Therefore, we can fix the problem by, instead of testing on each individual run, testing on each pair of consecutive runs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb416504-29aa-471d-ba8f-2ebaf7e476c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_run_indices = np.floor(run_indices/2) ### The key change\n",
    "print('Old group indices', run_indices)\n",
    "print('New group indices', new_run_indices.astype('int'))\n",
    "\n",
    "for p in np.arange(npeople):\n",
    "    accuracy_per_fold = skl.model_selection.cross_val_score(pipe, data[p], fruits, groups = new_run_indices, cv = logo, scoring = 'balanced_accuracy')\n",
    "    fruit_accuracy[p] = np.mean(accuracy_per_fold)\n",
    "\n",
    "result = scipy.stats.ttest_1samp(fruit_accuracy, 0.5, alternative='two-sided')\n",
    "print(\"Mean accuracy of fruit classification across participants:\", np.mean(fruit_accuracy))\n",
    "print(f't({result.df}) = {result.statistic:.2f}; p = {result.pvalue:.2e}')\n",
    "\n",
    "ax = sns.histplot(fruit_accuracy, element='step', alpha = 0.3, color = 'r')\n",
    "ax.set(xlabel = 'accuracy of fruit classification')\n",
    "ax.set(ylabel = 'count of participants')\n",
    "lh = ax.axvline(0.5, color='k',label='chance')\n",
    "mh = ax.plot(np.mean(fruit_accuracy), 0, marker = 'o', color = 'r', markersize = 10, label='observed mean')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8567e04b-7416-4aba-aae8-c5bd81215d04",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "The accuracy of fruit decoding is now no longer significantly different from chance, consistent with the simulation.\n",
    "\n",
    "(Note that extra folds could be added, that test on pairs of any odd numbered run combined with any even-numbered run, without requiring that these are consecutive. This would increase the robustness of the estimated performance scores, but would be more fiddly to set up.  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5735856c-e237-4b61-a2cf-81b83078ab28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
