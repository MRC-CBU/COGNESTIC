{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83b5cd7d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<h1><span style=\"color:green\">The GREEN exercise</span></h1>\n",
    "\n",
    "Patterns from each of ***two classes have been drawn from distributions with the same mean***. I.e. on average the patterns associated with each class are identical, and typically we would not want to conclude that the classes differ. However, a simple classification has been run for each of 40 participants, and the ***classifier accuracy is significantly above chance***. \n",
    "\n",
    "***Is this correct?*** \n",
    "\n",
    "***Change the analysis so that it no longer finds a significant difference between the classes.***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676fa9e3-0335-403f-b51f-b7f31f6d64a6",
   "metadata": {},
   "source": [
    "## Getting ready\n",
    "\n",
    "Import the packages we might need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85ab6c8-b515-4737-bd94-62f57c593db5",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np              # This lets python process matrices, like Matlab\n",
    "import matplotlib.pyplot as plt # This lets python plot graphs like Matlab\n",
    "import seaborn as sns           # This provides another popular set of plotting functions\n",
    "import scipy                    # This provides scientific capabilities like t-tests\n",
    "\n",
    "# scikit-learn is the major library for machine learning in Python:\n",
    "import sklearn as skl\n",
    "from sklearn import preprocessing         # includes LabelEncoder, OneHotEncoder, StandardScaler...\n",
    "from sklearn import model_selection       # includes StratifiedKFold, LeaveOneGroupOut...\n",
    "from sklearn import linear_model          # includes LogisticRegression, RidgeClassifier...\n",
    "from sklearn import svm                   # includes SVC, NuSVC & LinearSCV...\n",
    "from sklearn import discriminant_analysis # includes LinearDiscriminantAnalysis\n",
    "from sklearn import metrics               # includes roc_auc_score...\n",
    "from sklearn import pipeline              # includes make_pipeline\n",
    "from sklearn import inspection            # includes DecisionBoundaryDisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3d8900-3d80-4e46-88f9-f52743b6f84a",
   "metadata": {},
   "source": [
    "Set the random number generator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8fa6fb7-c5db-45b5-9cdf-f2498b2cb02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555754ff-edff-4067-9dd6-0a5892a61141",
   "metadata": {},
   "source": [
    "## Simulate some data (two, balanced classes) with no mean difference between conditions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ec4e92-80d4-4765-ba54-02b82a7726d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "npeople = 40 # number of participants\n",
    "\n",
    "nvox = 2 # number of voxels\n",
    "nruns= 6 # number of runs\n",
    "n_samples_per_run = 10 # number of samples/patterns per run; these will be divided into conditions/classes \"0\" and \"1\"\n",
    "proportion_of_samples_from_condition_0 = 0.5\n",
    "\n",
    "mu = np.arange(nvox)+1 # mean activation for both conditions (voxels all have different activation strength)\n",
    "voxel_covariance = np.diag(mu)+1 # voxel covariance: independent noise per voxel plus some covariance\n",
    "\n",
    "null_data = [] # list of pattern matrices (one per participant)\n",
    "\n",
    "for p in np.arange(npeople):\n",
    "    \n",
    "    null_data_per_run = [] # list of pattern matrices (one for each run)\n",
    "    labels_per_run    = [] # list of label vectors    (one for each run)\n",
    "    for r in np.arange(nruns):\n",
    "        # label each sample as condition 0 or 1 (the +0 is a trick to convert the logical values to integers):\n",
    "        label_vector= ((np.arange(n_samples_per_run)/n_samples_per_run)>=proportion_of_samples_from_condition_0) + 0;\n",
    "        \n",
    "        # sample activations with patterns from each class having the same mean (mu):\n",
    "        data_matrix0 =  np.random.multivariate_normal(mu, voxel_covariance,   size=np.sum(label_vector == 0))\n",
    "        data_matrix1 =  np.random.multivariate_normal(mu, voxel_covariance*8, size=np.sum(label_vector == 1))\n",
    "        data_matrix  =  np.concatenate((data_matrix0, data_matrix1))\n",
    "        \n",
    "        null_data_per_run.append( data_matrix ) \n",
    "        labels_per_run.append( label_vector ) \n",
    "    \n",
    "    # concatenate runs for this participant\n",
    "    null_data.append(   np.concatenate(null_data_per_run, axis = 0) )\n",
    "\n",
    "# same for all particiapnts:\n",
    "labels =      np.concatenate(labels_per_run, axis = 0) \n",
    "run_indices = np.concatenate([[i] * n_samples_per_run for i in range(nruns)]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06279146-6e6f-46cb-9f16-3efe54bff475",
   "metadata": {},
   "source": [
    "\\\n",
    "Plot the data for the first two voxels of the first participant:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d11414-0ac2-44b0-a259-aeaeda7742da",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (8,8))  # create a matplotlib figure\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "plt.title('Activation patterns for first two voxels')\n",
    "scatter = plt.scatter(null_data[0][:,[0]], null_data[0][:,[1]], \n",
    "                      s = 90, alpha = 0.7, c = labels, cmap = 'bwr')\n",
    "plt.legend(handles=scatter.legend_elements()[0], labels=set(np.unique(labels))) # \"set\" returns unique values\n",
    "plt.xlabel('Voxel 1 activity')\n",
    "plt.ylabel('Voxel 2 activity')\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb0ad01-6494-4aa8-9bc8-9b1682bc4cf2",
   "metadata": {},
   "source": [
    "\\\n",
    "Specify the pre-processing, classification pipeline, and leave-one-run-out cross-validation scheme:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95deed99-2fc6-44e8-88c0-2f8abf1929c8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler = skl.preprocessing.StandardScaler()\n",
    "SVM    = skl.svm.SVC()\n",
    "pipe   = skl.pipeline.make_pipeline(scaler, SVM)\n",
    "logo   = skl.model_selection.LeaveOneGroupOut()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb89cfe5-da13-438e-8c36-ab9476b37575",
   "metadata": {},
   "source": [
    "\\\n",
    "Run the classification for each participant:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38e94d3-9c5c-4970-9fb4-fe70c8e31b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = np.full(npeople, np.nan)\n",
    "for p in np.arange(npeople):\n",
    "    accuracy_per_fold = skl.model_selection.cross_val_score(pipe, null_data[p], labels, groups = run_indices, cv = logo, scoring = 'balanced_accuracy')\n",
    "    accuracy[p] = np.mean(accuracy_per_fold)\n",
    "    print(\"Participant \", p, \": Accuracy per fold: \", accuracy_per_fold, \"Mean accuracy (for random data):\", accuracy[p])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe99d88-787f-4464-807e-ba9b18b99c95",
   "metadata": {},
   "source": [
    "\\\n",
    "Run a one-sample t-test across participants and find a significant difference between classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a5ce4a-1d41-4e41-a6aa-d66039c4af58",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = scipy.stats.ttest_1samp(accuracy, 0.5, alternative = 'greater')\n",
    "print(\"Mean accuracy across participants (for random data):\", np.mean(accuracy))\n",
    "print(f't({result.df}) = {result.statistic:.2f}; p = {result.pvalue:.2e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b103960-2663-42ef-a824-4d04d894d9d5",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Questions:\n",
    " - We have two classes, drawn from distributions with the same mean pattern, so why is accuracy not close to 0.5?\n",
    " - Is the classifier performing as it should?\n",
    " - Can you change the analysis to get a classification score closer to a level equivalent to 50% accuracy?\n",
    "\n",
    "## Hints:\n",
    "- Consider the data that is being provided to the classifier per class.\n",
    "- What classifier is being used? Consider other options when creating it.\n",
    "- Is there a \"better\" way to measure classifier performance in this case?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c034b979-0994-49b7-b11f-b6fc67875ccb",
   "metadata": {},
   "source": [
    "# Explanation and possible solutions:\n",
    "\n",
    "The two classes come from distributions with the same *mean*, but *different variances*. Classifiers can typically use information in the variance to distinguish the classes. Sometimes, two representations might meaningfully differ in their variance, and the brain might be able to use this information, and we might be interested in capturing it. However, classes can also often have different variance for uninteresting reasons: one condition might be based on fewer trials; particpants might move more in one condition; participants might pay more attention in one condition, etc.\n",
    "\n",
    "The classifier is doing exactly what it is supposed to: maximizing its average classification performance. The issue is that the classifier can use information in the pattern variance, whereas we might only be interested in the mean pattern.\n",
    "\n",
    "The classifier used in the example is a support vector machine (SVM) initialised with no input arguments. This defaults to a non-linear (radial basis function) classifier, which is very sensitive to class variance. Let's visualise its classification boundary for one participant:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5dc2c8e-53b6-4a8f-88e1-a1ba1212a2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM.fit(null_data[0], labels)\n",
    "skl.inspection.DecisionBoundaryDisplay.from_estimator(SVM, null_data[0], \n",
    "                                                      alpha = 0.5, ax = fig.axes[0], cmap = 'bwr', response_method = 'predict');\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9825b039-8432-402f-8dba-ac5ae7cda1c0",
   "metadata": {},
   "source": [
    "\\\n",
    "A simpler, linear classifier is less prone to overfitting (which is typically better for fMRI data anyway), and is also less sensitive to differences in pattern variance. A linear SVM can be specified like this:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ca0356-1a6c-45b9-832a-6ad3e0abe3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM    = skl.svm.SVC(kernel = 'linear') ##################### The change\n",
    "pipe   = skl.pipeline.make_pipeline(scaler, SVM)\n",
    "\n",
    "for p in np.arange(npeople):\n",
    "    accuracy_per_fold = skl.model_selection.cross_val_score(pipe, null_data[p], labels, groups  = run_indices, cv = logo, scoring = 'balanced_accuracy')\n",
    "    accuracy[p] = np.mean(accuracy_per_fold)\n",
    "    \n",
    "result = scipy.stats.ttest_1samp(accuracy, 0.5, alternative = 'greater')\n",
    "print(\"Mean accuracy across participants (for random data):\", np.mean(accuracy))\n",
    "print(f't({result.df}) = {result.statistic:.2f}; p = {result.pvalue:.2e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa108644-0007-41ab-838a-c46738b1eadf",
   "metadata": {},
   "source": [
    "\\\n",
    "Accuracy is closer to chance, but still significantly above chance.\n",
    "\n",
    "This is because the decision boundary can be placed to the side of the tighter cluster. This means it will be correct all of the time for the tight cluster, while still being correct some of the time for the noisier cluster:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c311cc5-61dc-42f6-9e74-2725b42e5ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (8,8))  # create a matplotlib figure\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "plt.title('Activation patterns for first two voxels')\n",
    "scatter = plt.scatter(null_data[0][:,[0]], null_data[0][:,[1]], \n",
    "                      s = 90, alpha = 0.7, c = labels, cmap = 'bwr')\n",
    "plt.legend(handles=scatter.legend_elements()[0], labels=set(np.unique(labels))) # \"set\" returns unique values\n",
    "plt.xlabel('Voxel 1 activity')\n",
    "plt.ylabel('Voxel 2 activity')\n",
    "plt.axis('equal')\n",
    "\n",
    "SVM.fit(null_data[0], labels)\n",
    "skl.inspection.DecisionBoundaryDisplay.from_estimator(SVM, null_data[0], \n",
    "                                                      alpha = 0.5, ax = fig.axes[0], cmap = 'bwr', response_method = 'predict');\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a63f37-802a-4882-8563-71ab5c6d000e",
   "metadata": {},
   "source": [
    "\\\n",
    "There is another way to specify a linear SVM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4470af38-6406-4bfd-99fe-407f7fe19ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM    = skl.svm.LinearSVC(dual = 'auto') ##################### The change\n",
    "pipe   = skl.pipeline.make_pipeline(scaler, SVM)\n",
    "\n",
    "for p in np.arange(npeople):\n",
    "    accuracy_per_fold = skl.model_selection.cross_val_score(pipe, null_data[p], labels, groups  = run_indices, cv = logo, scoring = 'balanced_accuracy')\n",
    "    accuracy[p] = np.mean(accuracy_per_fold)\n",
    "    \n",
    "result = scipy.stats.ttest_1samp(accuracy, 0.5, alternative = 'greater')\n",
    "print(\"Mean accuracy across participants (for random data):\", np.mean(accuracy))\n",
    "print(f't({result.df}) = {result.statistic:.2f}; p = {result.pvalue:.2e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576f7f87-74d8-4a8a-8a2b-d15bf716bdb1",
   "metadata": {},
   "source": [
    "This time the accuracy is much closer to chance, but still signficantly above chance. I'm not sure of the exact difference between these two implementations of a linear SVM, or why they seem to have different sensitivity to pattern variance. If you know, please tell me!\n",
    "\n",
    "Anyway, the accuracy of a linear classifier is less sensitive to differences in pattern variance than the accuracy of a non-linear classifier, but still has some sensitivity to pattern variance.\n",
    "\n",
    "\\\n",
    "For linear classifiers, a performance metric that should, on average, be insensitive to pattern variance is the mean signed distance to the decision boundary, where the sign is positive for correct classifications and negative for misclassifications. This metric should have an expectation of zero, under the null hypothesis of no mean difference in patterns, regardless of pattern variance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755ab8ff-4d8f-4186-a801-8eef4769caa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "signed_decisions = np.full(npeople, np.nan)\n",
    "for p in np.arange(npeople):\n",
    "    decisions = skl.model_selection.cross_val_predict(pipe, null_data[p], labels, groups = run_indices, cv = logo, method = 'decision_function')\n",
    "    # For a linear classifier, these are distances of each test sample to the hyperplane, with the sign indicating the predicted class.\n",
    "    # To get a measure of performance, we want the sign to indicate accuracy:\n",
    "    predictions = skl.model_selection.cross_val_predict(pipe, null_data[p], labels, groups = run_indices, cv = logo, method = 'predict') # binary class assignments\n",
    "    accuracy = (predictions == labels)*2-1   # +1 for correct, -1 for incorrect\n",
    "    signed_decisions_per_sample = np.abs(decisions) * accuracy\n",
    "    signed_decisions[p] = np.mean(signed_decisions_per_sample)\n",
    "\n",
    "result = scipy.stats.ttest_1samp(signed_decisions, 0, alternative = 'greater')\n",
    "print(\"Mean signed distance to hyperplane across participants (for random data):\", np.mean(signed_decisions))\n",
    "print(f't({result.df}) = {result.statistic:.2f}; p = {result.pvalue:.2e}')\n",
    "\n",
    "ax = sns.histplot(signed_decisions_per_sample, element = 'step', alpha = 0.5)\n",
    "ax.set(xlabel = 'Mean signed distance to hyperplane');\n",
    "ax.set(title = 'Example participant');\n",
    "lh = ax.axvline(0, color = 'k',label = 'chance')\n",
    "mh = ax.plot(np.mean(signed_decisions_per_sample), 0, marker = 'o', color = 'r', markersize = 10, label = 'observed mean')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23a4538-cdf8-4309-89b9-80e291acaa52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
