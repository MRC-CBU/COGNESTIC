{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Co-registration of EEG/MEG with MRI coordinate frames\n",
    "\n",
    "This notebook shows how to co-register coordinate frames for EEG/MEG sensor\n",
    "locations and MRI images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook is based on MNE-Python tutorials and examples, e.g.\n",
    "# https://mne.tools/stable/auto_tutorials/forward/20_source_alignment.html\n",
    "# https://mne.tools/stable/auto_tutorials/forward/25_automated_coreg.html\n",
    "\n",
    "# Modified by Olaf Hauk, olaf.hauk@mrc-cbu.cam.ac.uk\n",
    "# These notebooks complement the online lectures \"Introduction to EEG/MEG analysis\":\n",
    "# https://www.youtube.com/playlist?list=PLp67eqWCj2f_DBsCMkIOBpBbLWGAUKtu5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file C:\\Users\\olaf\\mne_data\\MNE-sample-data\\MEG\\sample\\sample_audvis_raw.fif...\n",
      "    Read a total of 3 projection items:\n",
      "        PCA-v1 (1 x 102)  idle\n",
      "        PCA-v2 (1 x 102)  idle\n",
      "        PCA-v3 (1 x 102)  idle\n",
      "    Range : 25800 ... 192599 =     42.956 ...   320.670 secs\n",
      "Ready.\n",
      "    Reading a source space...\n",
      "    Computing patch statistics...\n",
      "    Patch information added...\n",
      "    Distance information added...\n",
      "    [done]\n",
      "    Reading a source space...\n",
      "    Computing patch statistics...\n",
      "    Patch information added...\n",
      "    Distance information added...\n",
      "    [done]\n",
      "    2 source spaces read\n"
     ]
    }
   ],
   "source": [
    "import nibabel as nib\n",
    "import numpy as np\n",
    "from scipy import linalg\n",
    "\n",
    "import mne\n",
    "from mne.io.constants import FIFF\n",
    "\n",
    "data_path = mne.datasets.sample.data_path()\n",
    "subjects_dir = data_path / \"subjects\"\n",
    "raw_fname = data_path / \"MEG\" / \"sample\" / \"sample_audvis_raw.fif\"\n",
    "trans_fname = data_path / \"MEG\" / \"sample\" / \"sample_audvis_raw-trans.fif\"\n",
    "raw = mne.io.read_raw_fif(raw_fname)\n",
    "trans = mne.read_trans(trans_fname)\n",
    "src = mne.read_source_spaces(subjects_dir / \"sample\" / \"bem\" / \"sample-oct-6-src.fif\")\n",
    "\n",
    "# Load the T1 file and change the header information to the correct units\n",
    "t1w = nib.load(data_path / \"subjects\" / \"sample\" / \"mri\" / \"T1.mgz\")\n",
    "t1w = nib.Nifti1Image(t1w.dataobj, t1w.affine)\n",
    "t1w.header[\"xyzt_units\"] = np.array(10, dtype=\"uint8\")\n",
    "t1_mgh = nib.MGHImage(t1w.dataobj, t1w.affine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".. raw:: html\n",
    "\n",
    "   <style>\n",
    "   .pink {color:DarkSalmon; font-weight:bold}\n",
    "   .blue {color:DeepSkyBlue; font-weight:bold}\n",
    "   .gray {color:Gray; font-weight:bold}\n",
    "   .magenta {color:Magenta; font-weight:bold}\n",
    "   .purple {color:Indigo; font-weight:bold}\n",
    "   .green {color:LimeGreen; font-weight:bold}\n",
    "   .red {color:Red; font-weight:bold}\n",
    "   </style>\n",
    "\n",
    ".. role:: pink\n",
    ".. role:: blue\n",
    ".. role:: gray\n",
    ".. role:: magenta\n",
    ".. role:: purple\n",
    ".. role:: green\n",
    ".. role:: red\n",
    "\n",
    "\n",
    "## Understanding coordinate frames\n",
    "For M/EEG source imaging, there are three **coordinate frames** must be\n",
    "brought into alignment using two 3D [transformation matrices](wiki_xform_)\n",
    "that define how to rotate and translate points in one coordinate frame\n",
    "to their equivalent locations in another. The three main coordinate frames\n",
    "are:\n",
    "\n",
    "* :blue:`\"meg\"`: the coordinate frame for the physical locations of MEG sensors\n",
    "* :gray:`\"mri\"`: the coordinate frame for MRI images, and scalp/skull/brain\n",
    "  surfaces derived from the MRI images\n",
    "* :pink:`\"head\"`: the coordinate frame for digitized sensor locations and\n",
    "  scalp landmarks (\"fiducials\")\n",
    "\n",
    "\n",
    "Each of these are described in more detail in the next section.\n",
    "\n",
    "A good way to start visualizing these coordinate frames is to use the\n",
    "`mne.viz.plot_alignment` function, which is used for creating or inspecting\n",
    "the transformations that bring these coordinate frames into alignment, and\n",
    "displaying the resulting alignment of EEG sensors, MEG sensors, brain\n",
    "sources, and conductor models. If you provide ``subjects_dir`` and\n",
    "``subject`` parameters, the function automatically loads the subject's\n",
    "Freesurfer MRI surfaces. Important for our purposes, passing\n",
    "``show_axes=True`` to `~mne.viz.plot_alignment` will draw the origin of each\n",
    "coordinate frame in a different color, with axes indicated by different sized\n",
    "arrows:\n",
    "\n",
    "* shortest arrow: (**R**)ight / X\n",
    "* medium arrow: forward / (**A**)nterior / Y\n",
    "* longest arrow: up / (**S**)uperior / Z\n",
    "\n",
    "Note that all three coordinate systems are **RAS** coordinate frames and\n",
    "hence are also `right-handed`_ coordinate systems. Finally, note that the\n",
    "``coord_frame`` parameter sets which coordinate frame the camera\n",
    "should initially be aligned with. Let's have a look:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using pyvistaqt 3d backend.\n",
      "False\n",
      "Using lh.seghead for head surface.\n",
      "Channel types::\tgrad: 203, mag: 102\n",
      "Distance from head origin to MEG origin: 65.0 mm\n",
      "Distance from head origin to MRI origin: 29.9 mm\n",
      "Using surface from C:\\Users\\olaf\\mne_data\\MNE-sample-data\\subjects\\sample\\bem\\sample-head.fif.\n",
      "Distance from 72 digitized points to head surface: 1.7 mm\n"
     ]
    }
   ],
   "source": [
    "fig = mne.viz.plot_alignment(\n",
    "    raw.info,\n",
    "    trans=trans,\n",
    "    subject=\"sample\",\n",
    "    subjects_dir=subjects_dir,\n",
    "    surfaces=\"head-dense\",\n",
    "    show_axes=True,\n",
    "    dig=True,\n",
    "    eeg=[],\n",
    "    meg=\"sensors\",\n",
    "    coord_frame=\"meg\",\n",
    "    mri_fiducials=\"estimated\",\n",
    ")\n",
    "mne.viz.set_3d_view(fig, 45, 90, distance=0.6, focalpoint=(0.0, 0.0, 0.0))\n",
    "print(\n",
    "    \"Distance from head origin to MEG origin: %0.1f mm\"\n",
    "    % (1000 * np.linalg.norm(raw.info[\"dev_head_t\"][\"trans\"][:3, 3]))\n",
    ")\n",
    "print(\n",
    "    \"Distance from head origin to MRI origin: %0.1f mm\"\n",
    "    % (1000 * np.linalg.norm(trans[\"trans\"][:3, 3]))\n",
    ")\n",
    "dists = mne.dig_mri_distances(raw.info, trans, \"sample\", subjects_dir=subjects_dir)\n",
    "print(\n",
    "    f\"Distance from {len(dists)} digitized points to head surface: \"\n",
    "    f\"{1000 * np.mean(dists):0.1f} mm\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coordinate frame definitions\n",
    "1. Neuromag/Elekta/MEGIN head coordinate frame (\"head\", :pink:`pink axes`)\n",
    "     The head coordinate frame is defined through the coordinates of\n",
    "     anatomical landmarks on the subject's head: usually the Nasion (`NAS`_),\n",
    "     and the left and right preauricular points (`LPA`_ and `RPA`_).\n",
    "     Different MEG manufacturers may have different definitions of the head\n",
    "     coordinate frame. A good overview can be seen in the\n",
    "     `FieldTrip FAQ on coordinate systems`_.\n",
    "\n",
    "     For Neuromag/Elekta/MEGIN, the head coordinate frame is defined by the\n",
    "     intersection of\n",
    "\n",
    "     1. the line between the LPA (:red:`red sphere`) and RPA\n",
    "        (:purple:`purple sphere`), and\n",
    "     2. the line perpendicular to this LPA-RPA line one that goes through\n",
    "        the Nasion (:green:`green sphere`).\n",
    "\n",
    "     The axes are oriented as **X** origin→RPA, **Y** origin→NAS,\n",
    "     **Z** origin→upward (orthogonal to X and Y).\n",
    "\n",
    "     .. note:: The required 3D coordinates for defining the head coordinate\n",
    "               frame (NAS, LPA, RPA) are measured at a stage separate from\n",
    "               the MEG data recording. There exist numerous devices to\n",
    "               perform such measurements, usually called \"digitizers\". For\n",
    "               example, see the devices by the company `Polhemus`_.\n",
    "\n",
    "2. MEG device coordinate frame (\"meg\", :blue:`blue axes`)\n",
    "     The MEG device coordinate frame is defined by the respective MEG\n",
    "     manufacturers. All MEG data is acquired with respect to this coordinate\n",
    "     frame. To account for the anatomy and position of the subject's head, we\n",
    "     use so-called head position indicator (HPI) coils. The HPI coils are\n",
    "     placed at known locations on the scalp of the subject and emit\n",
    "     high-frequency magnetic fields used to coregister the head coordinate\n",
    "     frame with the device coordinate frame.\n",
    "\n",
    "     From the Neuromag/Elekta/MEGIN user manual:\n",
    "\n",
    "         The origin of the device coordinate system is located at the center\n",
    "         of the posterior spherical section of the helmet with X axis going\n",
    "         from left to right and Y axis pointing front. The Z axis is, again\n",
    "         normal to the plane with positive direction up.\n",
    "\n",
    "     .. note:: The HPI coils are shown as :magenta:`magenta spheres`.\n",
    "               Coregistration happens at the beginning of the recording and\n",
    "               the head↔meg transformation matrix is stored in\n",
    "               ``raw.info['dev_head_t']``.\n",
    "\n",
    "3. MRI coordinate frame (\"mri\", :gray:`gray axes`)\n",
    "     Defined by Freesurfer, the \"MRI surface RAS\" coordinate frame has its\n",
    "     origin at the center of a 256×256×256 1mm anisotropic volume (though the\n",
    "     center may not correspond to the anatomical center of the subject's\n",
    "     head).\n",
    "\n",
    "     .. note:: We typically align the MRI coordinate frame to the head\n",
    "               coordinate frame through a [rotation and translation matrix](wiki_xform_), that we refer to in MNE as ``trans``."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A bad example\n",
    "Let's try using `~mne.viz.plot_alignment` by making ``trans`` the identity\n",
    "transform. This (incorrectly!) equates the MRI and head coordinate frames.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "Using lh.seghead for head surface.\n",
      "Getting helmet for system 306m\n",
      "Channel types::\tgrad: 203, mag: 102, eeg: 59\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<mne.viz.backends._pyvista.PyVistaFigure at 0x1c888a74b30>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "identity_trans = mne.transforms.Transform(\"head\", \"mri\")\n",
    "mne.viz.plot_alignment(\n",
    "    raw.info,\n",
    "    trans=identity_trans,\n",
    "    subject=\"sample\",\n",
    "    src=src,\n",
    "    subjects_dir=subjects_dir,\n",
    "    dig=True,\n",
    "    surfaces=[\"head-dense\", \"white\"],\n",
    "    coord_frame=\"meg\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A good example\n",
    "Here is the same plot, this time with the ``trans`` properly defined\n",
    "(using a precomputed transformation matrix).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "Using lh.seghead for head surface.\n",
      "Getting helmet for system 306m\n",
      "Channel types::\tgrad: 203, mag: 102, eeg: 59\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<mne.viz.backends._pyvista.PyVistaFigure at 0x1c8885d6c60>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mne.viz.plot_alignment(\n",
    "    raw.info,\n",
    "    trans=trans,\n",
    "    subject=\"sample\",\n",
    "    src=src,\n",
    "    subjects_dir=subjects_dir,\n",
    "    dig=True,\n",
    "    surfaces=[\"head-dense\", \"white\"],\n",
    "    coord_frame=\"meg\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Defining the head↔MRI ``trans`` using the GUI\n",
    "You can try creating the head↔MRI transform yourself using\n",
    ":func:`mne.gui.coregistration`.\n",
    "\n",
    "* To set the MRI fiducials, make sure ``Lock Fiducials`` is toggled off.\n",
    "* Set the landmarks by clicking the radio button (LPA, Nasion, RPA) and then\n",
    "  clicking the corresponding point in the image.\n",
    "\n",
    "<div class=\"alert alert-info\"><h4>Note</h4><p>The position of each fiducial used is the center of the octahedron icon.</p></div>\n",
    "\n",
    "* After doing this for all the landmarks, toggle ``Lock Fiducials`` radio\n",
    "  button and optionally pressing ``Save MRI Fid.`` which will save to a\n",
    "  default location in the ``bem`` folder of the Freesurfer subject directory.\n",
    "* Then you can load the digitization data from the raw file\n",
    "  (``Path to info``).\n",
    "* Click ``Fit ICP``. This will align the digitization points to the\n",
    "  head surface. Sometimes the fitting algorithm doesn't find the correct\n",
    "  alignment immediately. You can try first fitting using LPA/RPA or fiducials\n",
    "  and then align according to the digitization. You can also finetune\n",
    "  manually with the controls on the right side of the panel.\n",
    "* Click ``Save`` (lower right corner of the panel), set the filename\n",
    "  and read it with :func:`mne.read_trans`.\n",
    "\n",
    "For more information, see this video:\n",
    "\n",
    ".. youtube:: ALV5qqMHLlQ\n",
    "\n",
    "<div class=\"alert alert-info\"><h4>Note</h4><p>Coregistration can also be automated as shown in `tut-auto-coreg`.</p></div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "    Triangle neighbors and vertex normals...\n",
      "Using high resolution head model in C:\\Users\\olaf\\mne_data\\MNE-sample-data\\subjects\\sample\\surf\\lh.seghead\n",
      "    Triangle neighbors and vertex normals...\n",
      "Using fiducials from: C:\\Users\\olaf\\mne_data\\MNE-sample-data\\subjects\\sample\\bem\\sample-fiducials.fif.\n",
      "Using high resolution head model in C:\\Users\\olaf\\mne_data\\MNE-sample-data\\subjects\\fsaverage\\bem\\fsaverage-head-dense.fif\n",
      "    Triangle neighbors and vertex normals...\n",
      "Using fiducials from: C:\\Users\\olaf\\mne_data\\MNE-sample-data\\subjects\\fsaverage\\bem\\fsaverage-fiducials.fif.\n",
      "Loading MRI fiducials from C:\\Users\\olaf\\mne_data\\MNE-sample-data\\subjects\\fsaverage\\bem\\fsaverage-fiducials.fif... Done!\n",
      "    Triangle neighbors and vertex normals...\n",
      "Using high resolution head model in C:\\Users\\olaf\\mne_data\\MNE-sample-data\\subjects\\sample\\surf\\lh.seghead\n",
      "    Triangle neighbors and vertex normals...\n",
      "Using fiducials from: C:\\Users\\olaf\\mne_data\\MNE-sample-data\\subjects\\sample\\bem\\sample-fiducials.fif.\n",
      "Loading MRI fiducials from C:\\Users\\olaf\\mne_data\\MNE-sample-data\\subjects\\sample\\bem\\sample-fiducials.fif... Done!\n",
      "Using lh.seghead for head surface.\n",
      "Loading MRI fiducials from C:\\Users\\olaf\\mne_data\\MNE-sample-data\\subjects\\sample\\bem\\sample-fiducials.fif... Done!\n",
      "Using lh.seghead for head surface.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<mne.gui._coreg.CoregistrationUI at 0x1c888c3cbc0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start the GUI for co-registration\n",
    "mne.gui.coregistration(subject=\"sample\", subjects_dir=subjects_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible to use :func:`mne.gui.coregistration`\n",
    "to warp a subject (usually ``fsaverage``) to subject digitization data. Note that you can use the \"MRI Scaling\" options to (non-)linearly rescale the transformation (see\n",
    "[these slides](https://www.slideshare.net/mne-python/mnepython-scale-mri)).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "Using high resolution head model in C:\\Users\\olaf\\mne_data\\MNE-sample-data\\subjects\\fsaverage\\bem\\fsaverage-head-dense.fif\n",
      "    Triangle neighbors and vertex normals...\n",
      "Using fiducials from: C:\\Users\\olaf\\mne_data\\MNE-sample-data\\subjects\\fsaverage\\bem\\fsaverage-fiducials.fif.\n",
      "Using high resolution head model in C:\\Users\\olaf\\mne_data\\MNE-sample-data\\subjects\\fsaverage\\bem\\fsaverage-head-dense.fif\n",
      "    Triangle neighbors and vertex normals...\n",
      "Using fiducials from: C:\\Users\\olaf\\mne_data\\MNE-sample-data\\subjects\\fsaverage\\bem\\fsaverage-fiducials.fif.\n",
      "Loading MRI fiducials from C:\\Users\\olaf\\mne_data\\MNE-sample-data\\subjects\\fsaverage\\bem\\fsaverage-fiducials.fif... Done!\n",
      "Using fsaverage-head-dense.fif for head surface.\n",
      "    1 BEM surfaces found\n",
      "    Reading a surface...\n",
      "[done]\n",
      "    1 BEM surfaces read\n",
      "Loading MRI fiducials from C:\\Users\\olaf\\mne_data\\MNE-sample-data\\subjects\\fsaverage\\bem\\fsaverage-fiducials.fif... Done!\n",
      "Using fsaverage-head-dense.fif for head surface.\n",
      "    1 BEM surfaces found\n",
      "    Reading a surface...\n",
      "[done]\n",
      "    1 BEM surfaces read\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<mne.gui._coreg.CoregistrationUI at 0x1c86fc88c20>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use Freesurfer's fsaverage brain for co-registration\n",
    "mne.gui.coregistration(subject=\"fsaverage\", subjects_dir=subjects_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
