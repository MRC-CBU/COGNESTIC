{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d0bec7d",
   "metadata": {},
   "source": [
    "- **Author:** [Dace Apšvalka](https://www.mrc-cbu.cam.ac.uk/people/dace.apsvalka/) \n",
    "- **Date:** August 2024  \n",
    "- **conda environment**: I used the [fMRI workshop's conda environment](https://github.com/MRC-CBU/COGNESTIC/blob/main/mri_environment.yml) to run this notebook and any accompanied scripts.\n",
    "\n",
    "# fMRI Data Quality Control and Pre-processing\n",
    "\n",
    "--------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23ea8d9",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "1. [Quality control with MRIQC](#toc1_)    \n",
    "1.1. [MRIQC Participant level](#toc1_1_)    \n",
    "1.2. [MRIQC Group level](#toc1_2_)    \n",
    "1.3. [MRIQC output](#toc1_3_)    \n",
    "2. [Preprocessing with fMRIPrep](#toc2_)    \n",
    "2.1. [Preprocessing of structural MRI](#toc2_1_)    \n",
    "2.2. [BOLD preprocessing](#toc2_2_)    \n",
    "2.3. [fMRIPrep generated Methods section](#toc2_3_)    \n",
    "2.4. [Example scipt to run fMRIPrep](#toc2_4_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=true\n",
    "\tanchor=true\n",
    "\tflat=true\n",
    "\tminLevel=2\n",
    "\tmaxLevel=3\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50950fb",
   "metadata": {},
   "source": [
    "-----------\n",
    "\n",
    "## 1. <a id='toc1_'></a>[Quality control with MRIQC](#toc0_)\n",
    "Before we start to do anything with our data, we should check the acquisition quality. \n",
    "\n",
    "**MRIQC** extracts various [IQMs (image quality metrics)](https://mriqc.readthedocs.io/en/latest/measures.html) from structural (T1w and T2w) and functional MRI (magnetic resonance imaging) data.\n",
    "\n",
    "See [MRIQC Documentation](https://mriqc.readthedocs.io/en/latest/).\n",
    "\n",
    "MRIQC is a [BIDS-App](https://bids-apps.neuroimaging.io/), and therefore it inherently understands the BIDS standard and follows the BIDS-Apps standard command line interface: \n",
    "\n",
    "`mriqc bids-root/ output-folder/ participant`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8f34f1",
   "metadata": {},
   "source": [
    "The most effective way to run MRIQC is through containerized versions, such as Docker or Singularity/Apptainer. Containers encapsulate the software and all its dependencies, including a minimal operating system, within a single comprehensive image. This ensures that when it's time to run the software, everything operates seamlessly. The use of containers enhances the shareability and portability of the software, leading to more reproducible outputs. At the CBU, we have access to Singularity/Apptainer, which is also available on HPC systems. Importantly, Singularity/Apptainer can utilize Docker images as well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113d460a",
   "metadata": {},
   "source": [
    "### 1.1. <a id='toc1_1_'></a>[MRIQC Participant level](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e5d0d4",
   "metadata": {},
   "source": [
    "**Example generic script:** [code-examples/mriqc_script.sh(code-examples/mriqc_script.sh)]\n",
    "\n",
    "The script in brief:\n",
    "\n",
    "```bash\n",
    "...\n",
    "\n",
    "# ======================================================================\n",
    "# MRIQC with Singularity\n",
    "# ======================================================================\n",
    "singularity run \\\n",
    "    -B \"$PROJECT_PATH\":/MyProject \\\n",
    "    /imaging/local/software/singularity_images/mriqc/mriqc-22.0.1.simg \\\n",
    "    /MyProject/data \\\n",
    "    /MyProject/data/derivatives/mriqc/ \\\n",
    "    --work-dir /MyProject/scratch/mriqc/\"$subject\" \\\n",
    "    participant \\\n",
    "    --participant-label \"${subject#sub-}\" \\\n",
    "    --float32 \\\n",
    "    --n_procs 16 --mem_gb 24 --ants-nthreads 16 \\\n",
    "    --modalities T1w bold \\\n",
    "    --no-sub\n",
    "\n",
    "# EACH LINE EXPLINED:\n",
    "# attaching our project directory to the Singularity\n",
    "# the Singularity file\n",
    "# our BIDS data directory\n",
    "# output directory\n",
    "# --work-dir: path where intermediate results should be stored\n",
    "# analysis_level (participant or group)\n",
    "# --participant-label: a list of participant identifiers\n",
    "# --float32: cast the input data to float32 if it’s represented in higher precision (saves space and improves perfomance)\n",
    "# --n_procs 16 --mem_gb 24 --ants-nthreads 16: options to handle performance\n",
    "# --modalities: filter input dataset by MRI type\n",
    "# --no-sub: turn off submission of anonymized quality metrics to MRIQC’s metrics repository\n",
    "# ======================================================================\n",
    "\n",
    "```\n",
    "\n",
    "**Example script for processing multiple subjects using SLURM**: [code-examples/step05_mriqc_subjects.sh](code-examples/step05_mriqc_subjects.sh)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4c280b",
   "metadata": {},
   "source": [
    "### 1.2. <a id='toc1_2_'></a>[MRIQC Group level](#toc0_)\n",
    "\n",
    "The 'Goup' level just aggregates subject level reports and links them together."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bfbf152",
   "metadata": {},
   "source": [
    "**Example script:** [code-examples/step06_mriqc_group.sh](code-examples/step06_mriqc_group.sh)\n",
    "\n",
    "```bash\n",
    "\n",
    "PROJECT_PATH='FaceProcessing'\n",
    "\n",
    "# ======================================================================\n",
    "# MRIQC with Singularity\n",
    "# ======================================================================\n",
    "singularity run --cleanenv -B \"$PROJECT_PATH\":/\"$PROJECT_PATH\" \\\n",
    "    /imaging/local/software/singularity_images/mriqc/mriqc-22.0.1.simg \\\n",
    "    \"$PROJECT_PATH\"/data \"$PROJECT_PATH\"/data/derivatives/mriqc/ \\\n",
    "    --work-dir \"$PROJECT_PATH\"/work/mriqc/ \\\n",
    "    group \\\n",
    "    --float32 \\\n",
    "    --n_procs 16 --mem_gb 24 \\\n",
    "    --ants-nthreads 16 \\\n",
    "    --modalities T1w bold \\\n",
    "    --no-sub\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0c0e14",
   "metadata": {},
   "source": [
    "### 1.3. <a id='toc1_3_'></a>[MRIQC output](#toc0_)\n",
    "\n",
    "`MRIQC` output is [`BIDS` **derivative**](https://bids-specification.readthedocs.io/en/stable/05-derivatives/01-introduction.html). Derivatives are outputs of common processing pipelines, capturing data and meta-data sufficient for a researcher to understand and (critically) reuse those outputs in subsequent processing.\n",
    "\n",
    "`MRIQC` outputs separate `MRIQC` reports for each individual run, as well as group reports. To have a quick look at the quality of the data acquired for your subjects, a good first start is to look at the group bold report to see if the image quality metrics show any outlier runs with respect to the quality of the data of your whole sample.\n",
    "\n",
    "Here is an informative paper about MRI *carpet plots*: [Power, J. D. (2017). A simple but useful way to assess fMRI scan qualities. Neuroimage, 154, 150-158.](https://doi.org/10.1016/j.neuroimage.2016.08.009)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9a2cc4",
   "metadata": {},
   "source": [
    "## 2. <a id='toc2_'></a>[Preprocessing with fMRIPrep](#toc0_)\n",
    "\n",
    "`fMRIprep` ([A Robust Preprocessing Pipeline for fMRI Data](https://fmriprep.org/en/stable/) is another [BIDS-App](https://bids-apps.neuroimaging.io/). \n",
    "\n",
    "fMRIPrep is a fMRI data preprocessing pipeline that is designed to provide an easily accessible, state-of-the-art interface that is robust to variations in scan acquisition protocols and that requires **minimal user input**, while providing easily interpretable and comprehensive error and output reporting. \n",
    "\n",
    "The fMRIPrep pipeline uses a combination of tools from well-known software packages, including FSL, ANTs, FreeSurfer and AFNI. This pipeline was designed to **provide the best software implementation for each state of preprocessing**.\n",
    "\n",
    "fMRIPrep performs **minimal preprocessing**: motion correction, field unwarping, normalization, bias field correction, and brain extraction. [See the workflows section of our documentation for more details](https://fmriprep.org/en/latest/workflows.html).\n",
    "\n",
    "fMRIPrep adapts its pipeline depending on what data and metadata are available and are used as the input. For example, slice timing correction will be performed only if the `SliceTiming` metadata field is found for the input dataset.\n",
    "\n",
    "### 2.1. <a id='toc2_1_'></a>[Preprocessing of structural MRI](#toc0_)\n",
    "\n",
    "Steps: \n",
    "* Brain extraction (skull-stripping; helps with normalisation), \n",
    "* brain tissue segmentation (needed for normalisation) and \n",
    "* spatial normalisation.\n",
    "\n",
    "#### Lesion masking during normalisation\n",
    "\n",
    "When processing images from patients with focal brain lesions (e.g., stroke, tumor resection), it is possible to provide a lesion mask to be used during spatial normalization to standard space. The mask will be used to minimize warping of healthy tissue into damaged areas (or vice-versa). Lesion masks should be binary NIfTI images (damaged areas = 1, everywhere else = 0) in the same space and resolution as the T1 image, and follow the naming convention specified in [BIDS Extension Proposal 3: Common Derivatives](https://docs.google.com/document/d/1Wwc4A6Mow4ZPPszDIWfCUCRNstn7d_zzaWPcfcHmgI4/edit#heading=h.9146wuepclkt) (e.g., `sub-001_T1w_label-lesion_roi.nii.gz`). This file should be placed in the `sub-*/anat` directory of the BIDS dataset to be run through fMRIPrep. Because lesion masks are not currently part of the BIDS specification, it is also necessary to include a `.bidsignore` file in the root of your dataset directory. This will prevent bids-validator from complaining that your dataset is not valid BIDS, which prevents fMRIPrep from running. Your `.bidsignore` file should include the following line: `*lesion_roi.nii.gz`\n",
    "\n",
    "#### Surface preprocessing\n",
    "fMRIPrep uses [FreeSurfer](https://surfer.nmr.mgh.harvard.edu/) to reconstruct surfaces from T1w/T2w structural images. If enabled, several steps in the fMRIPrep pipeline are added or replaced. All surface preprocessing may be disabled with the `--fs-no-reconall` flag.\n",
    "\n",
    "### 2.2. <a id='toc2_2_'></a>[BOLD preprocessing](#toc0_)\n",
    "\n",
    "#### BOLD reference image estimation\n",
    "\n",
    "The reference image is used to calculate a brain mask for the BOLD signal, estimate head-motion, and register BOLD to T1w.  \n",
    "\n",
    "If a single-band reference (“sbref”) image associated with the BOLD series is available, then it is used directly. If not, a reference image is estimated from the BOLD series as follows: When T1-saturation effects (“dummy scans” or non-steady state volumes) are detected, they are averaged and used as reference due to their superior tissue contrast. Otherwise, a median of motion corrected subset of volumes is used.\n",
    "\n",
    "\n",
    "#### Head-motion estimation\n",
    "\n",
    "Using the previously estimated reference scan, FSL `mcflirt` is used to estimate head-motion. For a more accurate estimation of head-motion, the motion parameters are calculated before any time-domain filtering (i.e., slice-timing correction).\n",
    "\n",
    "#### Slice time correction\n",
    "\n",
    "If the `SliceTiming` field is available within the input dataset metadata, this workflow performs slice time correction prior to other signal resampling processes. Slice time correction is performed using AFNI `3dTShift`. All slices are realigned in time to the **middle of each TR**.\n",
    "\n",
    "Slice time correction can be disabled with the `--ignore slicetiming` command line argument.\n",
    "\n",
    "#### Susceptibility Distortion Correction\n",
    "\n",
    "One of the major problems that affects EPI data is the spatial distortion caused by the inhomogeneity of the field inside the scanner. This step applies susceptibility-derived distortion correction, based on fieldmap estimation. \n",
    "\n",
    "#### Pre-processed BOLD in native space\n",
    "\n",
    "A new *preproc* BOLD series is generated from the slice-timing corrected (or the original) data in the original space.\n",
    "\n",
    "#### EPI to T1w registration\n",
    "\n",
    "The alignment between the reference EPI image of each run and the reconstructed subject using the gray/white matter boundary is calculated by the `bbregister` routine. If FreeSurfer processing is disabled, FSL `flirt` is run with the BBR cost function.\n",
    "\n",
    "#### Resampling BOLD runs to standard spaces\n",
    "\n",
    "EPI image is mapped to the standard spaces given by the `--output-spaces` argument (see [Defining standard and nonstandard spaces where data will be resampled](https://fmriprep.org/en/latest/spaces.html#output-spaces)).\n",
    "\n",
    "#### EPI sampled to FreeSurfer surfaces\n",
    "\n",
    "If FreeSurfer processing is enabled, the motion-corrected functional series (after single shot resampling to T1w space) is sampled to the surface by averaging across the cortical ribbon.\n",
    "\n",
    "Surfaces are generated for the “subject native” surface, as well as transformed to the `fsaverage` template space. All surface outputs are in GIFTI format.\n",
    "\n",
    "#### Confounds estimation\n",
    "\n",
    "Non-neuronal fluctuations in fMRI data may appear as a result of head motion, scanner noise, or physiological fluctuations (related to cardiac or respiratory effects). For a detailed review of the possible sources of noise in the BOLD signal, see [Greve et al. (2013)](https://doi.org/10.1007/s11336-012-9294-0). \n",
    "\n",
    "Given a motion-corrected fMRI, a brain mask, movement parameters and a segmentation, potential confounds per volume (time-point) are calculated. Confounding variables calculated in fMRIPrep are stored separately for each subject, session and run in `.tsv` files - one column for each confound variable. Such tabular files may include over 100 columns of potential confound regressors.\n",
    "\n",
    "It is possible to minimize confounding effects of non-neuronal signals by including them as nuisance regressors in the GLM design matrix. The fMRIPrep pipeline generates a large array of possible confounds. The most well established confounding variables in neuroimaging are the six head-motion parameters (three rotations and three translations) - the common output of the head-motion correction (also known as realignment) of popular fMRI preprocessing software such as SPM or FSL. \n",
    "\n",
    "**Do not include all columns of `~_desc-confounds_timeseries.tsv` table into your design matrix! Filter the table first, to include only the confounds you want to remove from your fMRI signal.** [See the fMRIPrep confound regressor description](https://fmriprep.org/en/latest/outputs.html#confound-regressors-description). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d352709",
   "metadata": {},
   "source": [
    "### 2.3. <a id='toc2_3_'></a>[fMRIPrep generated Methods section](#toc0_)\n",
    "\n",
    ">Results included in this manuscript come from preprocessing\n",
    "performed using *fMRIPrep* 21.0.1\n",
    "(@fmriprep1; @fmriprep2; RRID:SCR_016216),\n",
    "which is based on *Nipype* 1.6.1\n",
    "(@nipype1; @nipype2; RRID:SCR_002502).\n",
    "\n",
    "\n",
    "\n",
    ">Preprocessing of B<sub>0</sub> inhomogeneity mappings\n",
    "\n",
    ">: A total of 1 fieldmaps were found available within the input\n",
    "BIDS structure for this particular subject.\n",
    "A *B<sub>0</sub>* nonuniformity map (or *fieldmap*) was estimated from the\n",
    "phase-drift map(s) measure with two consecutive GRE (gradient-recalled echo)\n",
    "acquisitions.\n",
    "The corresponding phase-map(s) were phase-unwrapped with `prelude` (FSL 6.0.5.1:57b01774).\n",
    "\n",
    ">Anatomical data preprocessing\n",
    "\n",
    ">: A total of 1 T1-weighted (T1w) images were found within the input\n",
    "BIDS dataset.The T1-weighted (T1w) image was corrected for intensity non-uniformity (INU)\n",
    "with `N4BiasFieldCorrection` [@n4], distributed with ANTs 2.3.3 [@ants, RRID:SCR_004757], and used as T1w-reference throughout the workflow.\n",
    "The T1w-reference was then skull-stripped with a *Nipype* implementation of\n",
    "the `antsBrainExtraction.sh` workflow (from ANTs), using OASIS30ANTs\n",
    "as target template.\n",
    "Brain tissue segmentation of cerebrospinal fluid (CSF),\n",
    "white-matter (WM) and gray-matter (GM) was performed on\n",
    "the brain-extracted T1w using `fast` [FSL 6.0.5.1:57b01774, RRID:SCR_002823,\n",
    "@fsl_fast].\n",
    "Brain surfaces were reconstructed using `recon-all` [FreeSurfer 6.0.1,\n",
    "RRID:SCR_001847, @fs_reconall], and the brain mask estimated\n",
    "previously was refined with a custom variation of the method to reconcile\n",
    "ANTs-derived and FreeSurfer-derived segmentations of the cortical\n",
    "gray-matter of Mindboggle [RRID:SCR_002438, @mindboggle].\n",
    "Volume-based spatial normalization to one standard space (MNI152NLin2009cAsym) was performed through\n",
    "nonlinear registration with `antsRegistration` (ANTs 2.3.3),\n",
    "using brain-extracted versions of both T1w reference and the T1w template.\n",
    "The following template was selected for spatial normalization:\n",
    "*ICBM 152 Nonlinear Asymmetrical template version 2009c* [@mni152nlin2009casym, RRID:SCR_008796; TemplateFlow ID: MNI152NLin2009cAsym].\n",
    "\n",
    ">Functional data preprocessing\n",
    "\n",
    ">: For each of the 9 BOLD runs found per subject (across all\n",
    "tasks and sessions), the following preprocessing was performed.\n",
    "First, a reference volume and its skull-stripped version were generated\n",
    " using a custom\n",
    "methodology of *fMRIPrep*.\n",
    "Head-motion parameters with respect to the BOLD reference\n",
    "(transformation matrices, and six corresponding rotation and translation\n",
    "parameters) are estimated before any spatiotemporal filtering using\n",
    "`mcflirt` [FSL 6.0.5.1:57b01774, @mcflirt].\n",
    "The estimated *fieldmap* was then aligned with rigid-registration to the target\n",
    "EPI (echo-planar imaging) reference run.\n",
    "The field coefficients were mapped on to the reference EPI using the transform.\n",
    "BOLD runs were slice-time corrected to 0.974s (0.5 of slice acquisition range\n",
    "0s-1.95s) using `3dTshift` from AFNI  [@afni, RRID:SCR_005927].\n",
    "The BOLD reference was then co-registered to the T1w reference using\n",
    "`bbregister` (FreeSurfer) which implements boundary-based registration [@bbr].\n",
    "Co-registration was configured with six degrees of freedom.\n",
    "Several confounding time-series were calculated based on the\n",
    "*preprocessed BOLD*: framewise displacement (FD), DVARS and\n",
    "three region-wise global signals.\n",
    "FD was computed using two formulations following Power (absolute sum of\n",
    "relative motions, @power_fd_dvars) and Jenkinson (relative root mean square\n",
    "displacement between affines, @mcflirt).\n",
    "FD and DVARS are calculated for each functional run, both using their\n",
    "implementations in *Nipype* [following the definitions by @power_fd_dvars].\n",
    "The three global signals are extracted within the CSF, the WM, and\n",
    "the whole-brain masks.\n",
    "Additionally, a set of physiological regressors were extracted to\n",
    "allow for component-based noise correction [*CompCor*, @compcor].\n",
    "Principal components are estimated after high-pass filtering the\n",
    "*preprocessed BOLD* time-series (using a discrete cosine filter with\n",
    "128s cut-off) for the two *CompCor* variants: temporal (tCompCor)\n",
    "and anatomical (aCompCor).\n",
    "tCompCor components are then calculated from the top 2% variable\n",
    "voxels within the brain mask.\n",
    "For aCompCor, three probabilistic masks (CSF, WM and combined CSF+WM)\n",
    "are generated in anatomical space.\n",
    "The implementation differs from that of Behzadi et al. in that instead\n",
    "of eroding the masks by 2 pixels on BOLD space, the aCompCor masks are\n",
    "subtracted a mask of pixels that likely contain a volume fraction of GM.\n",
    "This mask is obtained by dilating a GM mask extracted from the FreeSurfer's *aseg* segmentation, and it ensures components are not extracted\n",
    "from voxels containing a minimal fraction of GM.\n",
    "Finally, these masks are resampled into BOLD space and binarized by\n",
    "thresholding at 0.99 (as in the original implementation).\n",
    "Components are also calculated separately within the WM and CSF masks.\n",
    "For each CompCor decomposition, the *k* components with the largest singular\n",
    "values are retained, such that the retained components' time series are\n",
    "sufficient to explain 50 percent of variance across the nuisance mask (CSF,\n",
    "WM, combined, or temporal). The remaining components are dropped from\n",
    "consideration.\n",
    "The head-motion estimates calculated in the correction step were also\n",
    "placed within the corresponding confounds file.\n",
    "The confound time series derived from head motion estimates and global\n",
    "signals were expanded with the inclusion of temporal derivatives and\n",
    "quadratic terms for each [@confounds_satterthwaite_2013].\n",
    "Frames that exceeded a threshold of 0.5 mm FD or\n",
    "1.5 standardised DVARS were annotated as motion outliers.\n",
    "The BOLD time-series were resampled into standard space,\n",
    "generating a *preprocessed BOLD run in MNI152NLin2009cAsym space*.\n",
    "First, a reference volume and its skull-stripped version were generated\n",
    " using a custom\n",
    "methodology of *fMRIPrep*.\n",
    "All resamplings can be performed with *a single interpolation\n",
    "step* by composing all the pertinent transformations (i.e. head-motion\n",
    "transform matrices, susceptibility distortion correction when available,\n",
    "and co-registrations to anatomical and output spaces).\n",
    "Gridded (volumetric) resamplings were performed using `antsApplyTransforms` (ANTs),\n",
    "configured with Lanczos interpolation to minimize the smoothing\n",
    "effects of other kernels [@lanczos].\n",
    "Non-gridded (surface) resamplings were performed using `mri_vol2surf`\n",
    "(FreeSurfer).\n",
    "\n",
    ">Many internal operations of *fMRIPrep* use\n",
    "*Nilearn* 0.8.1 [@nilearn, RRID:SCR_001362],\n",
    "mostly within the functional processing workflow.\n",
    "For more details of the pipeline, see [the section corresponding\n",
    "to workflows in *fMRIPrep*'s documentation](https://fmriprep.readthedocs.io/en/latest/workflows.html \"FMRIPrep's documentation\")."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c778ae6",
   "metadata": {},
   "source": [
    "### 2.4. <a id='toc2_4_'></a>[Example scipt to run fMRIPrep](#toc0_)\n",
    "\n",
    "If you want to include Freesurfer surface reconstruction, you need to get [Freesurfer license file](https://surfer.nmr.mgh.harvard.edu/registration.html) (it is free!).\n",
    "\n",
    "If you want to skip the Freesurfer part, specify `--fs-no-reconall` (although, you might still need to have the Freesurfer license!).\n",
    "\n",
    "About `--output-spaces` see information [here](https://fmriprep.org/en/22.0.1/spaces.html).\n",
    "\n",
    "See the list of all possible options [here](https://fmriprep.org/en/stable/usage.html#execution-and-the-bids-format).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ef640e",
   "metadata": {},
   "source": [
    "**Example of a generic script:** [code-examples/fmriprep_script.sh](code-examples/fmriprep_script.sh)\n",
    "\n",
    "```bash\n",
    "# ...\n",
    "# See the possible fmriprep arguments here: https://fmriprep.org/en/stable/usage.html\n",
    "\n",
    "singularity run \\\n",
    "    -B \"$PROJECT_PATH\":/MyProject \\\n",
    "    /imaging/local/software/singularity_images/fmriprep/fmriprep-21.0.1.simg \\\n",
    "    /MyProject/data \\\n",
    "    /MyProject/data/derivatives/fmriprep\\\n",
    "    participant \\\n",
    "    --fs-license-file /MyProject/code/freesurfer_license.txt \\\n",
    "    --work-dir /MyProject/scratch/fmriprep \\\n",
    "    --participant-label \"$subject\" \\\n",
    "    --output-spaces MNI152NLin2009cAsym:res-2 \\\n",
    "    --dummy-scans 2 \\\n",
    "    --fs-no-reconall \\\n",
    "    --nthreads 16 --omp-nthreads 8 \\\n",
    "    --skip-bids-validation \\\n",
    "    --stop-on-first-crash\n",
    "```\n",
    "\n",
    "**Example script for processing multiple subjects using SLURM:** [code-examples/step07_fmriprep.sh](code-examples/step07_fmriprep.sh)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa38520",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "340.167px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
